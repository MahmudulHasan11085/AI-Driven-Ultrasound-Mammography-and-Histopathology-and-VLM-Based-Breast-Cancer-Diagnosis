{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0c4a9c",
   "metadata": {
    "papermill": {
     "duration": 0.013116,
     "end_time": "2025-04-08T09:20:15.765863",
     "exception": false,
     "start_time": "2025-04-08T09:20:15.752747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b3aa19",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:15.791328Z",
     "iopub.status.busy": "2025-04-08T09:20:15.791067Z",
     "iopub.status.idle": "2025-04-08T09:20:29.666625Z",
     "shell.execute_reply": "2025-04-08T09:20:29.665960Z"
    },
    "papermill": {
     "duration": 13.890196,
     "end_time": "2025-04-08T09:20:29.668348",
     "exception": false,
     "start_time": "2025-04-08T09:20:15.778152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from timm import create_model\n",
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from timm.layers import Conv2dSame\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "seed = 42  \n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0635de",
   "metadata": {
    "papermill": {
     "duration": 0.020024,
     "end_time": "2025-04-08T09:20:29.709576",
     "exception": false,
     "start_time": "2025-04-08T09:20:29.689552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266e554b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:29.742125Z",
     "iopub.status.busy": "2025-04-08T09:20:29.741480Z",
     "iopub.status.idle": "2025-04-08T09:20:29.823432Z",
     "shell.execute_reply": "2025-04-08T09:20:29.822567Z"
    },
    "papermill": {
     "duration": 0.10014,
     "end_time": "2025-04-08T09:20:29.824854",
     "exception": false,
     "start_time": "2025-04-08T09:20:29.724714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_index = {'benign': 0, 'malignant': 1}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size_1 = 8\n",
    "epochs = 100\n",
    "train_losses_fold1 = []\n",
    "train_losses_fold2 = []\n",
    "train_losses_fold3 = []\n",
    "train_losses_fold4 = []\n",
    "train_losses_fold5 = []\n",
    "valid_accuracy_scores_fold1 = []\n",
    "valid_accuracy_scores_fold2 = []\n",
    "valid_accuracy_scores_fold3 = []\n",
    "valid_accuracy_scores_fold4 = []\n",
    "valid_accuracy_scores_fold5 = []\n",
    "best_val_acc = 0\n",
    "Model_Path_Folds = [\n",
    "    'Best_Epoch_Accuracy_Fold1',\n",
    "    'Best_Epoch_Accuracy_Fold2',\n",
    "    'Best_Epoch_Accuracy_Fold3',\n",
    "    'Best_Epoch_Accuracy_Fold4',\n",
    "    'Best_Epoch_Accuracy_Fold5'\n",
    "]\n",
    "k_folds = 5\n",
    "random_state = 42\n",
    "kf = KFold(n_splits=k_folds, shuffle = True, random_state = random_state)\n",
    "splits = {}\n",
    "save = 0\n",
    "total_val_accuracy = 0\n",
    "total_val_precision = 0\n",
    "total_val_recall = 0\n",
    "total_val_specificity = 0\n",
    "total_val_f1 = 0\n",
    "total_val_mcc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3449bd",
   "metadata": {
    "papermill": {
     "duration": 0.011655,
     "end_time": "2025-04-08T09:20:29.848916",
     "exception": false,
     "start_time": "2025-04-08T09:20:29.837261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Assistive functions-1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99514708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:29.874036Z",
     "iopub.status.busy": "2025-04-08T09:20:29.873758Z",
     "iopub.status.idle": "2025-04-08T09:20:29.877533Z",
     "shell.execute_reply": "2025-04-08T09:20:29.876849Z"
    },
    "papermill": {
     "duration": 0.017548,
     "end_time": "2025-04-08T09:20:29.878669",
     "exception": false,
     "start_time": "2025-04-08T09:20:29.861121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freeze_stages(model, stage_indices):\n",
    "    for idx in stage_indices:\n",
    "        for param in model.stages[idx].parameters():\n",
    "            param.requires_grad = False\n",
    "        print(f\"Stage {idx} frozen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d59d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:29.903591Z",
     "iopub.status.busy": "2025-04-08T09:20:29.903379Z",
     "iopub.status.idle": "2025-04-08T09:20:41.041464Z",
     "shell.execute_reply": "2025-04-08T09:20:41.040768Z"
    },
    "papermill": {
     "duration": 11.151883,
     "end_time": "2025-04-08T09:20:41.042944",
     "exception": false,
     "start_time": "2025-04-08T09:20:29.891061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fceb78fc735744bfbd7e293eca98a830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/276M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maxvits_model1 = create_model('maxvit_small_tf_224.in1k', pretrained=True)\n",
    "maxvits_model1.head.fc = nn.Linear(maxvits_model1.head.in_features, 512).to(device)\n",
    "# freeze_stages(maxvits_model1, stage_indices=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8eeec",
   "metadata": {
    "papermill": {
     "duration": 0.011693,
     "end_time": "2025-04-08T09:20:41.067074",
     "exception": false,
     "start_time": "2025-04-08T09:20:41.055381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Image Model 1 (Ultrasound)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e42c617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:41.092255Z",
     "iopub.status.busy": "2025-04-08T09:20:41.092023Z",
     "iopub.status.idle": "2025-04-08T09:20:41.095740Z",
     "shell.execute_reply": "2025-04-08T09:20:41.095099Z"
    },
    "papermill": {
     "duration": 0.017961,
     "end_time": "2025-04-08T09:20:41.096818",
     "exception": false,
     "start_time": "2025-04-08T09:20:41.078857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Image_model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Image_model1,self).__init__()\n",
    "        self.model = maxvits_model1\n",
    "        \n",
    "    def forward(self,input1):\n",
    "        output = self.model(input1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02325f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:41.121246Z",
     "iopub.status.busy": "2025-04-08T09:20:41.121035Z",
     "iopub.status.idle": "2025-04-08T09:20:42.438724Z",
     "shell.execute_reply": "2025-04-08T09:20:42.437863Z"
    },
    "papermill": {
     "duration": 1.331691,
     "end_time": "2025-04-08T09:20:42.440215",
     "exception": false,
     "start_time": "2025-04-08T09:20:41.108524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                                            Output Shape              Param #\n",
       "===================================================================================================================\n",
       "Image_model1                                                      [2, 512]                  --\n",
       "├─MaxxVit: 1-1                                                    [2, 512]                  --\n",
       "│    └─Stem: 2-1                                                  [2, 64, 112, 112]         --\n",
       "│    │    └─Conv2dSame: 3-1                                       [2, 64, 112, 112]         1,792\n",
       "│    │    └─BatchNormAct2d: 3-2                                   [2, 64, 112, 112]         128\n",
       "│    │    └─Conv2d: 3-3                                           [2, 64, 112, 112]         36,928\n",
       "│    └─Sequential: 2-2                                            [2, 768, 7, 7]            --\n",
       "│    │    └─MaxxVitStage: 3-4                                     [2, 96, 56, 56]           638,972\n",
       "│    │    └─MaxxVitStage: 3-5                                     [2, 192, 28, 28]          2,488,248\n",
       "│    │    └─MaxxVitStage: 3-6                                     [2, 384, 14, 14]          25,030,296\n",
       "│    │    └─MaxxVitStage: 3-7                                     [2, 768, 7, 7]            39,370,464\n",
       "│    └─Identity: 2-3                                              [2, 768, 7, 7]            --\n",
       "│    └─NormMlpClassifierHead: 2-4                                 [2, 512]                  --\n",
       "│    │    └─SelectAdaptivePool2d: 3-8                             [2, 768, 1, 1]            --\n",
       "│    │    └─LayerNorm2d: 3-9                                      [2, 768, 1, 1]            1,536\n",
       "│    │    └─Flatten: 3-10                                         [2, 768]                  --\n",
       "│    │    └─Sequential: 3-11                                      [2, 768]                  590,592\n",
       "│    │    └─Dropout: 3-12                                         [2, 768]                  --\n",
       "│    │    └─Linear: 3-13                                          [2, 512]                  393,728\n",
       "===================================================================================================================\n",
       "Total params: 68,552,684\n",
       "Trainable params: 68,552,684\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 7.54\n",
       "===================================================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 815.37\n",
       "Params size (MB): 273.76\n",
       "Estimated Total Size (MB): 1090.33\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imgmodel1 = Image_model1()\n",
    "Imgmodel1 = Imgmodel1.to('cuda')\n",
    "summary(Imgmodel1,(2,3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f65a3",
   "metadata": {
    "papermill": {
     "duration": 0.012031,
     "end_time": "2025-04-08T09:20:42.464923",
     "exception": false,
     "start_time": "2025-04-08T09:20:42.452892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Assistive functions-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b63b70d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:42.489883Z",
     "iopub.status.busy": "2025-04-08T09:20:42.489635Z",
     "iopub.status.idle": "2025-04-08T09:20:43.931068Z",
     "shell.execute_reply": "2025-04-08T09:20:43.930297Z"
    },
    "papermill": {
     "duration": 1.45561,
     "end_time": "2025-04-08T09:20:43.932587",
     "exception": false,
     "start_time": "2025-04-08T09:20:42.476977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxvits_model2 = create_model('maxvit_small_tf_224.in1k', pretrained=True)\n",
    "maxvits_model2.stem.conv1 = Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
    "maxvits_model2.head.fc = nn.Linear(maxvits_model2.head.in_features, 512).to(device)\n",
    "# freeze_stages(maxvits_model2, stage_indices=[1])\n",
    "# maxvits_model3 = create_model('maxvit_small_tf_224.in1k', pretrained=True)\n",
    "# maxvits_model3.head.fc = nn.Linear(maxvits_model3.head.in_features, 512).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfac0c8",
   "metadata": {
    "papermill": {
     "duration": 0.012081,
     "end_time": "2025-04-08T09:20:43.958043",
     "exception": false,
     "start_time": "2025-04-08T09:20:43.945962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Image Model 2 (Mammogram)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1e6caae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:43.982928Z",
     "iopub.status.busy": "2025-04-08T09:20:43.982672Z",
     "iopub.status.idle": "2025-04-08T09:20:43.986255Z",
     "shell.execute_reply": "2025-04-08T09:20:43.985609Z"
    },
    "papermill": {
     "duration": 0.017389,
     "end_time": "2025-04-08T09:20:43.987453",
     "exception": false,
     "start_time": "2025-04-08T09:20:43.970064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Image_model21(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Image_model21,self).__init__()\n",
    "        self.model = maxvits_model2\n",
    "        \n",
    "    def forward(self,input1):\n",
    "        output = self.model(input1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a957c4b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:44.012432Z",
     "iopub.status.busy": "2025-04-08T09:20:44.012224Z",
     "iopub.status.idle": "2025-04-08T09:20:44.312976Z",
     "shell.execute_reply": "2025-04-08T09:20:44.312137Z"
    },
    "papermill": {
     "duration": 0.31488,
     "end_time": "2025-04-08T09:20:44.314392",
     "exception": false,
     "start_time": "2025-04-08T09:20:43.999512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                                            Output Shape              Param #\n",
       "===================================================================================================================\n",
       "Image_model21                                                     [2, 512]                  --\n",
       "├─MaxxVit: 1-1                                                    [2, 512]                  --\n",
       "│    └─Stem: 2-1                                                  [2, 64, 112, 112]         --\n",
       "│    │    └─Conv2dSame: 3-1                                       [2, 64, 112, 112]         1,792\n",
       "│    │    └─BatchNormAct2d: 3-2                                   [2, 64, 112, 112]         128\n",
       "│    │    └─Conv2d: 3-3                                           [2, 64, 112, 112]         36,928\n",
       "│    └─Sequential: 2-2                                            [2, 768, 7, 7]            --\n",
       "│    │    └─MaxxVitStage: 3-4                                     [2, 96, 56, 56]           638,972\n",
       "│    │    └─MaxxVitStage: 3-5                                     [2, 192, 28, 28]          2,488,248\n",
       "│    │    └─MaxxVitStage: 3-6                                     [2, 384, 14, 14]          25,030,296\n",
       "│    │    └─MaxxVitStage: 3-7                                     [2, 768, 7, 7]            39,370,464\n",
       "│    └─Identity: 2-3                                              [2, 768, 7, 7]            --\n",
       "│    └─NormMlpClassifierHead: 2-4                                 [2, 512]                  --\n",
       "│    │    └─SelectAdaptivePool2d: 3-8                             [2, 768, 1, 1]            --\n",
       "│    │    └─LayerNorm2d: 3-9                                      [2, 768, 1, 1]            1,536\n",
       "│    │    └─Flatten: 3-10                                         [2, 768]                  --\n",
       "│    │    └─Sequential: 3-11                                      [2, 768]                  590,592\n",
       "│    │    └─Dropout: 3-12                                         [2, 768]                  --\n",
       "│    │    └─Linear: 3-13                                          [2, 512]                  393,728\n",
       "===================================================================================================================\n",
       "Total params: 68,552,684\n",
       "Trainable params: 68,552,684\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 7.54\n",
       "===================================================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 815.37\n",
       "Params size (MB): 273.76\n",
       "Estimated Total Size (MB): 1090.33\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imgmodel21 = Image_model21()\n",
    "Imgmodel21 = Imgmodel21.to('cuda')\n",
    "summary(Imgmodel21,(2,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb245f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:44.341176Z",
     "iopub.status.busy": "2025-04-08T09:20:44.340922Z",
     "iopub.status.idle": "2025-04-08T09:20:44.343620Z",
     "shell.execute_reply": "2025-04-08T09:20:44.343054Z"
    },
    "papermill": {
     "duration": 0.017311,
     "end_time": "2025-04-08T09:20:44.344852",
     "exception": false,
     "start_time": "2025-04-08T09:20:44.327541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Image_model22(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Image_model22,self).__init__()\n",
    "#         self.model = maxvits_model3\n",
    "        \n",
    "#     def forward(self,input1):\n",
    "#         output = self.model(input1)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe6f78e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:44.371013Z",
     "iopub.status.busy": "2025-04-08T09:20:44.370784Z",
     "iopub.status.idle": "2025-04-08T09:20:44.373497Z",
     "shell.execute_reply": "2025-04-08T09:20:44.372914Z"
    },
    "papermill": {
     "duration": 0.016778,
     "end_time": "2025-04-08T09:20:44.374577",
     "exception": false,
     "start_time": "2025-04-08T09:20:44.357799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imgmodel22 = Image_model22()\n",
    "# Imgmodel22 = Imgmodel22.to('cuda')\n",
    "# summary(Imgmodel22,(2,3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d07f5f3",
   "metadata": {
    "papermill": {
     "duration": 0.012132,
     "end_time": "2025-04-08T09:20:44.399361",
     "exception": false,
     "start_time": "2025-04-08T09:20:44.387229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Assistive functions-3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d86642b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:44.424951Z",
     "iopub.status.busy": "2025-04-08T09:20:44.424662Z",
     "iopub.status.idle": "2025-04-08T09:20:45.815124Z",
     "shell.execute_reply": "2025-04-08T09:20:45.814194Z"
    },
    "papermill": {
     "duration": 1.405279,
     "end_time": "2025-04-08T09:20:45.817054",
     "exception": false,
     "start_time": "2025-04-08T09:20:44.411775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "maxvits_model4 = create_model('maxvit_small_tf_224.in1k', pretrained=True)\n",
    "maxvits_model4.stem.conv1 = Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
    "maxvits_model4.head.fc = nn.Linear(maxvits_model4.head.in_features, 512).to(device)\n",
    "# freeze_stages(maxvits_model4, stage_indices=[1])\n",
    "# maxvits_model5 = create_model('maxvit_small_tf_224.in1k', pretrained=True)\n",
    "# maxvits_model5.head.fc = nn.Linear(maxvits_model5.head.in_features, 512).to(device)\n",
    "# maxvits_model6 = create_model('maxvit_small_tf_224.in1k', pretrained=True)\n",
    "# maxvits_model6.head.fc = nn.Linear(maxvits_model6.head.in_features, 512).to(device)\n",
    "# maxvits_model7 = create_model('maxvit_small_tf_224.in1k', pretrained=True)\n",
    "# maxvits_model7.head.fc = nn.Linear(maxvits_model6.head.in_features, 512).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d82a1",
   "metadata": {
    "papermill": {
     "duration": 0.012807,
     "end_time": "2025-04-08T09:20:45.851103",
     "exception": false,
     "start_time": "2025-04-08T09:20:45.838296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Image Model 3 (Microscopic)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2eeeded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:45.877014Z",
     "iopub.status.busy": "2025-04-08T09:20:45.876654Z",
     "iopub.status.idle": "2025-04-08T09:20:45.881442Z",
     "shell.execute_reply": "2025-04-08T09:20:45.880716Z"
    },
    "papermill": {
     "duration": 0.019288,
     "end_time": "2025-04-08T09:20:45.882816",
     "exception": false,
     "start_time": "2025-04-08T09:20:45.863528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Image_model31(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Image_model31,self).__init__()\n",
    "        self.model = maxvits_model4\n",
    "        \n",
    "    def forward(self,input1):\n",
    "        output = self.model(input1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "767c0c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:45.908257Z",
     "iopub.status.busy": "2025-04-08T09:20:45.907975Z",
     "iopub.status.idle": "2025-04-08T09:20:46.211996Z",
     "shell.execute_reply": "2025-04-08T09:20:46.211068Z"
    },
    "papermill": {
     "duration": 0.318232,
     "end_time": "2025-04-08T09:20:46.213368",
     "exception": false,
     "start_time": "2025-04-08T09:20:45.895136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                                            Output Shape              Param #\n",
       "===================================================================================================================\n",
       "Image_model31                                                     [2, 512]                  --\n",
       "├─MaxxVit: 1-1                                                    [2, 512]                  --\n",
       "│    └─Stem: 2-1                                                  [2, 64, 112, 112]         --\n",
       "│    │    └─Conv2dSame: 3-1                                       [2, 64, 112, 112]         1,792\n",
       "│    │    └─BatchNormAct2d: 3-2                                   [2, 64, 112, 112]         128\n",
       "│    │    └─Conv2d: 3-3                                           [2, 64, 112, 112]         36,928\n",
       "│    └─Sequential: 2-2                                            [2, 768, 7, 7]            --\n",
       "│    │    └─MaxxVitStage: 3-4                                     [2, 96, 56, 56]           638,972\n",
       "│    │    └─MaxxVitStage: 3-5                                     [2, 192, 28, 28]          2,488,248\n",
       "│    │    └─MaxxVitStage: 3-6                                     [2, 384, 14, 14]          25,030,296\n",
       "│    │    └─MaxxVitStage: 3-7                                     [2, 768, 7, 7]            39,370,464\n",
       "│    └─Identity: 2-3                                              [2, 768, 7, 7]            --\n",
       "│    └─NormMlpClassifierHead: 2-4                                 [2, 512]                  --\n",
       "│    │    └─SelectAdaptivePool2d: 3-8                             [2, 768, 1, 1]            --\n",
       "│    │    └─LayerNorm2d: 3-9                                      [2, 768, 1, 1]            1,536\n",
       "│    │    └─Flatten: 3-10                                         [2, 768]                  --\n",
       "│    │    └─Sequential: 3-11                                      [2, 768]                  590,592\n",
       "│    │    └─Dropout: 3-12                                         [2, 768]                  --\n",
       "│    │    └─Linear: 3-13                                          [2, 512]                  393,728\n",
       "===================================================================================================================\n",
       "Total params: 68,552,684\n",
       "Trainable params: 68,552,684\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 7.54\n",
       "===================================================================================================================\n",
       "Input size (MB): 1.20\n",
       "Forward/backward pass size (MB): 815.37\n",
       "Params size (MB): 273.76\n",
       "Estimated Total Size (MB): 1090.33\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imgmodel31 = Image_model31()\n",
    "Imgmodel31 = Imgmodel31.to('cuda')\n",
    "summary(Imgmodel31,(2,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3070799e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:46.241169Z",
     "iopub.status.busy": "2025-04-08T09:20:46.240835Z",
     "iopub.status.idle": "2025-04-08T09:20:46.244486Z",
     "shell.execute_reply": "2025-04-08T09:20:46.243509Z"
    },
    "papermill": {
     "duration": 0.018654,
     "end_time": "2025-04-08T09:20:46.245802",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.227148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Image_model32(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Image_model32,self).__init__()\n",
    "#         self.model = maxvits_model5\n",
    "        \n",
    "#     def forward(self,input1):\n",
    "#         output = self.model(input1)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "586dd6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:46.309163Z",
     "iopub.status.busy": "2025-04-08T09:20:46.308838Z",
     "iopub.status.idle": "2025-04-08T09:20:46.312063Z",
     "shell.execute_reply": "2025-04-08T09:20:46.311058Z"
    },
    "papermill": {
     "duration": 0.019011,
     "end_time": "2025-04-08T09:20:46.313446",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.294435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imgmodel32 = Image_model32()\n",
    "# Imgmodel32 = Imgmodel32.to('cuda')\n",
    "# summary(Imgmodel32,(2,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff51a96f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:46.339247Z",
     "iopub.status.busy": "2025-04-08T09:20:46.339034Z",
     "iopub.status.idle": "2025-04-08T09:20:46.342156Z",
     "shell.execute_reply": "2025-04-08T09:20:46.341252Z"
    },
    "papermill": {
     "duration": 0.017321,
     "end_time": "2025-04-08T09:20:46.343480",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.326159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Image_model33(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Image_model33,self).__init__()\n",
    "#         self.model = maxvits_model6\n",
    "        \n",
    "#     def forward(self,input1):\n",
    "#         output = self.model(input1)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4c70a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:46.369414Z",
     "iopub.status.busy": "2025-04-08T09:20:46.369212Z",
     "iopub.status.idle": "2025-04-08T09:20:46.372130Z",
     "shell.execute_reply": "2025-04-08T09:20:46.371344Z"
    },
    "papermill": {
     "duration": 0.017208,
     "end_time": "2025-04-08T09:20:46.373398",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.356190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imgmodel33 = Image_model33()\n",
    "# Imgmodel33 = Imgmodel33.to('cuda')\n",
    "# summary(Imgmodel33,(2,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f1b0c57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:46.399113Z",
     "iopub.status.busy": "2025-04-08T09:20:46.398908Z",
     "iopub.status.idle": "2025-04-08T09:20:46.401811Z",
     "shell.execute_reply": "2025-04-08T09:20:46.401031Z"
    },
    "papermill": {
     "duration": 0.017135,
     "end_time": "2025-04-08T09:20:46.403104",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.385969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Image_model34(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Image_model34,self).__init__()\n",
    "#         self.model = maxvits_model7\n",
    "        \n",
    "#     def forward(self,input1):\n",
    "#         output = self.model(input1)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1212b1d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:46.428677Z",
     "iopub.status.busy": "2025-04-08T09:20:46.428474Z",
     "iopub.status.idle": "2025-04-08T09:20:46.431408Z",
     "shell.execute_reply": "2025-04-08T09:20:46.430600Z"
    },
    "papermill": {
     "duration": 0.016953,
     "end_time": "2025-04-08T09:20:46.432556",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.415603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imgmodel34 = Image_model34()\n",
    "# Imgmodel34 = Imgmodel34.to('cuda')\n",
    "# summary(Imgmodel34,(2,3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9ed06",
   "metadata": {
    "papermill": {
     "duration": 0.012081,
     "end_time": "2025-04-08T09:20:46.457178",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.445097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Assistive functions - small language model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa8b71a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:46.482596Z",
     "iopub.status.busy": "2025-04-08T09:20:46.482372Z",
     "iopub.status.idle": "2025-04-08T09:20:46.486304Z",
     "shell.execute_reply": "2025-04-08T09:20:46.485460Z"
    },
    "papermill": {
     "duration": 0.017994,
     "end_time": "2025-04-08T09:20:46.487503",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.469509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b1be35",
   "metadata": {
    "papermill": {
     "duration": 0.012283,
     "end_time": "2025-04-08T09:20:46.512480",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.500197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Small language Model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b4c679e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:46.538542Z",
     "iopub.status.busy": "2025-04-08T09:20:46.538341Z",
     "iopub.status.idle": "2025-04-08T09:20:46.543604Z",
     "shell.execute_reply": "2025-04-08T09:20:46.543037Z"
    },
    "papermill": {
     "duration": 0.019446,
     "end_time": "2025-04-08T09:20:46.544805",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.525359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MiniBERTEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size=30522, embed_dim=512, num_heads=16, hidden_dim=256, num_layers=32):\n",
    "        super(MiniBERTEncoder, self).__init__()\n",
    "        \n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.position_embedding = nn.Embedding(768, embed_dim) \n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.pooler = nn.Linear(embed_dim, embed_dim)\n",
    "        #self.classifier = nn.Linear(embed_dim, 2)  \n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        seq_length = input_ids.shape[1]\n",
    "        positions = torch.arange(0, seq_length, device=input_ids.device).unsqueeze(0)\n",
    "        \n",
    "        token_embeddings = self.token_embedding(input_ids)\n",
    "        position_embeddings = self.position_embedding(positions)\n",
    "        \n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        encoded_output = self.transformer(embeddings)\n",
    "        pooled_output = self.pooler(encoded_output[:, 0,:]) \n",
    "        pooled_output = torch.tanh(pooled_output)\n",
    "        \n",
    "        #output = self.classifier(pooled_output)  \n",
    "        \n",
    "        # return output, pooled_output\n",
    "        return pooled_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6be06e41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:46.570128Z",
     "iopub.status.busy": "2025-04-08T09:20:46.569929Z",
     "iopub.status.idle": "2025-04-08T09:20:47.459448Z",
     "shell.execute_reply": "2025-04-08T09:20:47.458650Z"
    },
    "papermill": {
     "duration": 0.903745,
     "end_time": "2025-04-08T09:20:47.460865",
     "exception": false,
     "start_time": "2025-04-08T09:20:46.557120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "MiniBERTEncoder                                    [8, 512]                  --\n",
       "├─Embedding: 1-1                                   [8, 128, 512]             15,627,264\n",
       "├─Embedding: 1-2                                   [1, 128, 512]             393,216\n",
       "├─TransformerEncoder: 1-3                          [8, 128, 512]             --\n",
       "│    └─ModuleList: 2-1                             --                        --\n",
       "│    │    └─TransformerEncoderLayer: 3-1           [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-2           [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-3           [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-4           [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-5           [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-6           [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-7           [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-8           [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-9           [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-10          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-11          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-12          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-13          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-14          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-15          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-16          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-17          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-18          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-19          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-20          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-21          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-22          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-23          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-24          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-25          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-26          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-27          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-28          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-29          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-30          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-31          [8, 128, 512]             1,315,584\n",
       "│    │    └─TransformerEncoderLayer: 3-32          [8, 128, 512]             1,315,584\n",
       "├─Linear: 1-4                                      [8, 512]                  262,656\n",
       "====================================================================================================\n",
       "Total params: 58,381,824\n",
       "Trainable params: 58,381,824\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 195.34\n",
       "====================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 474.51\n",
       "Params size (MB): 99.05\n",
       "Estimated Total Size (MB): 573.57\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "dummy_model = MiniBERTEncoder()\n",
    "dummy_input = torch.randint(0, 30522, (8, 128)) \n",
    "summary(dummy_model, input_data=dummy_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa16983d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:47.487574Z",
     "iopub.status.busy": "2025-04-08T09:20:47.487338Z",
     "iopub.status.idle": "2025-04-08T09:20:47.788490Z",
     "shell.execute_reply": "2025-04-08T09:20:47.787774Z"
    },
    "papermill": {
     "duration": 0.315961,
     "end_time": "2025-04-08T09:20:47.789981",
     "exception": false,
     "start_time": "2025-04-08T09:20:47.474020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "slm_model = MiniBERTEncoder()\n",
    "slm_model = slm_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413547fb",
   "metadata": {
    "papermill": {
     "duration": 0.012405,
     "end_time": "2025-04-08T09:20:47.815686",
     "exception": false,
     "start_time": "2025-04-08T09:20:47.803281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Assistive functions - Large language model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02526acb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:47.841606Z",
     "iopub.status.busy": "2025-04-08T09:20:47.841351Z",
     "iopub.status.idle": "2025-04-08T09:20:47.845230Z",
     "shell.execute_reply": "2025-04-08T09:20:47.844234Z"
    },
    "papermill": {
     "duration": 0.018294,
     "end_time": "2025-04-08T09:20:47.846527",
     "exception": false,
     "start_time": "2025-04-08T09:20:47.828233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f726a2c8",
   "metadata": {
    "papermill": {
     "duration": 0.012648,
     "end_time": "2025-04-08T09:20:47.872147",
     "exception": false,
     "start_time": "2025-04-08T09:20:47.859499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Large language Model 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aac72b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:47.898614Z",
     "iopub.status.busy": "2025-04-08T09:20:47.898367Z",
     "iopub.status.idle": "2025-04-08T09:20:47.902155Z",
     "shell.execute_reply": "2025-04-08T09:20:47.901477Z"
    },
    "papermill": {
     "duration": 0.018405,
     "end_time": "2025-04-08T09:20:47.903417",
     "exception": false,
     "start_time": "2025-04-08T09:20:47.885012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a095f2c",
   "metadata": {
    "papermill": {
     "duration": 0.012531,
     "end_time": "2025-04-08T09:20:47.928792",
     "exception": false,
     "start_time": "2025-04-08T09:20:47.916261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Assistive functions of main model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5098c08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:47.955371Z",
     "iopub.status.busy": "2025-04-08T09:20:47.955118Z",
     "iopub.status.idle": "2025-04-08T09:20:47.960016Z",
     "shell.execute_reply": "2025-04-08T09:20:47.959201Z"
    },
    "papermill": {
     "duration": 0.019704,
     "end_time": "2025-04-08T09:20:47.961304",
     "exception": false,
     "start_time": "2025-04-08T09:20:47.941600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvFusionClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hidden_dim=512, \n",
    "                 num_classes=2):\n",
    "        super(ConvFusionClassifier, self).__init__()\n",
    "        self.fusion_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )  \n",
    "        \n",
    "    def forward(self, feat_a, feat_b):\n",
    "        fused = torch.cat([feat_a, feat_b], dim=-1)\n",
    "        out = self.fusion_mlp(fused)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ef958",
   "metadata": {
    "papermill": {
     "duration": 0.013079,
     "end_time": "2025-04-08T09:20:47.987048",
     "exception": false,
     "start_time": "2025-04-08T09:20:47.973969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Main Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12117be9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.013342Z",
     "iopub.status.busy": "2025-04-08T09:20:48.013106Z",
     "iopub.status.idle": "2025-04-08T09:20:48.020136Z",
     "shell.execute_reply": "2025-04-08T09:20:48.019339Z"
    },
    "papermill": {
     "duration": 0.021476,
     "end_time": "2025-04-08T09:20:48.021369",
     "exception": false,
     "start_time": "2025-04-08T09:20:47.999893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class v_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(v_model,self).__init__()\n",
    "        out_features = 512\n",
    "        num_classes = 2\n",
    "        modality_dropout_prob = 0.5\n",
    "        self.encoder_ultrasound       = Image_model1()\n",
    "        #self.encoder_mammogram1       = Image_model21()\n",
    "        # self.encoder_mammogram2       = Image_model22()\n",
    "        # self.encoder_microscopic1     = Image_model31()\n",
    "        # self.encoder_microscopic2     = Image_model32()\n",
    "        # self.encoder_microscopic3     = Image_model33()\n",
    "        # self.encoder_microscopic4     = Image_model34()\n",
    "        # self.placeholder_ultrasound   = torch.zeros(num_classes).to(device)\n",
    "        # self.placeholder_mammogram1   = torch.zeros(num_classes).to(device)\n",
    "        # # self.placeholder_mammogram2   = nn.Parameter(torch.zeros(out_features))\n",
    "        # self.placeholder_microscopic1 = torch.zeros(num_classes).to(device)\n",
    "        # self.placeholder_microscopic2 = nn.Parameter(torch.zeros(out_features))\n",
    "        # self.placeholder_microscopic3 = nn.Parameter(torch.zeros(out_features))\n",
    "        # self.placeholder_microscopic4 = nn.Parameter(torch.zeros(out_features))\n",
    "        \n",
    "        # self.fusion = nn.Sequential(\n",
    "        #     nn.Linear(num_classes * 3, num_classes),\n",
    "        # )\n",
    "        #self.classifier1 = nn.Linear(out_features, num_classes)\n",
    "        #self.classifier2 = nn.Linear(out_features, num_classes)\n",
    "        #self.classifier3 = nn.Linear(out_features, num_classes)\n",
    "        #self.modality_dropout_prob = modality_dropout_prob\n",
    "    def forward(self, ultrasound=None, mammogram1=None, mammogram2=None, microscopic1=None, microscopic2=None, microscopic3=None, microscopic4=None, training=True):\n",
    "        batch_size = None\n",
    "        # if mammogram1 is not None:\n",
    "        #     if mammogram2 is not None:\n",
    "        #         mammogram1 = torch.cat([mammogram1,mammogram2], dim=1)\n",
    "        # if microscopic1 is not None:\n",
    "        #     if microscopic2 is not None:\n",
    "        #         if microscopic3 is not None:\n",
    "        #             if microscopic4 is not None:\n",
    "        #                 microscopic1 = torch.cat([microscopic1,microscopic2,microscopic3,microscopic4],dim=1)\n",
    "        \n",
    "        # for modality in [ultrasound, mammogram1, microscopic1]:\n",
    "        #     if modality is not None:\n",
    "        #         batch_size = modality.size(0)\n",
    "        #         break\n",
    "        # if batch_size is None:\n",
    "        #     raise ValueError(\"At least one modality must be provided.\")\n",
    "\n",
    "        for modality in [ultrasound]:\n",
    "            if modality is not None:\n",
    "                batch_size = modality.size(0)\n",
    "                break\n",
    "        if batch_size is None:\n",
    "            raise ValueError(\"At least one modality must be provided.\")\n",
    "        \n",
    "        # device = ultrasound.device if ultrasound is not None else (\n",
    "        #          mammogram1.device if mammogram1 is not None else (\n",
    "        #          # mammogram2.device if mammogram2 is not None else (\n",
    "        #          microscopic1.device if microscopic1 is not None else None))\n",
    "        #          # ( microscopic2.device if microscopic2 is not None else (\n",
    "        #          # microscopic3.device if microscopic3 is not None else (\n",
    "        #          # microscopic4.device if microscopic4 is not None else None))))))\n",
    "\n",
    "        \n",
    "        if ultrasound is not None:\n",
    "            feat_ultrasound = self.encoder_ultrasound(ultrasound)\n",
    "            # feat_ultrasound = self.classifier1(feat_ultrasound)\n",
    "            \n",
    "            # if training:\n",
    "            #     #mask = (torch.rand(batch_size, 1, device=feat_ultrasound.device) < self.modality_dropout_prob).float()\n",
    "            #     feat_ultrasound = feat_ultrasound #+ mask * self.placeholder_ultrasound.unsqueeze(0).expand(batch_size, -1)\n",
    "        # else:\n",
    "        #     feat_ultrasound = self.placeholder_ultrasound.unsqueeze(0).expand(batch_size, -1)\n",
    "            \n",
    "        # if mammogram1 is not None:\n",
    "        #     feat_mammogram1 = self.encoder_mammogram1(mammogram1)\n",
    "        #     feat_mammogram1 = self.classifier2(feat_mammogram1)\n",
    "        #     # if training:\n",
    "        #     #     #mask = (torch.rand(batch_size, 1, device=feat_mammogram1.device) < self.modality_dropout_prob).float()\n",
    "        #     #     feat_mammogram1 =  feat_mammogram1 #+ mask * self.placeholder_mammogram1.unsqueeze(0).expand(batch_size, -1)\n",
    "        # else:\n",
    "        #     feat_mammogram1 = self.placeholder_mammogram1.unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "        # if mammogram2 is not None:\n",
    "        #     feat_mammogram2 = self.encoder_mammogram2(mammogram2)\n",
    "        #     if training:\n",
    "        #         mask = (torch.rand(batch_size, 1, device=feat_mammogram2.device) < self.modality_dropout_prob).float()\n",
    "        #         feat_mammogram2 = (1 - mask) * feat_mammogram2 + mask * self.placeholder_mammogram2.unsqueeze(0).expand(batch_size, -1)\n",
    "        # else:\n",
    "        #     feat_mammogram2 = self.placeholder_mammogram2.unsqueeze(0).expand(batch_size, -1)\n",
    "            \n",
    "        # if microscopic1 is not None:\n",
    "        #     feat_microscopic1 = self.encoder_microscopic1(microscopic1)\n",
    "        #     feat_microscopic1 = self.classifier3(feat_microscopic1)\n",
    "        #     # if training:\n",
    "        #     #     #mask = (torch.rand(batch_size, 1, device=feat_microscopic1.device) < self.modality_dropout_prob).float()\n",
    "        #     #     feat_microscopic1 =  feat_microscopic1 #+ mask * self.placeholder_microscopic1.unsqueeze(0).expand(batch_size, -1)\n",
    "        # else:\n",
    "        #     feat_microscopic1 = self.placeholder_microscopic1.unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "        # if microscopic2 is not None:\n",
    "        #     feat_microscopic2 = self.encoder_microscopic2(microscopic2)\n",
    "        #     if training:\n",
    "        #         mask = (torch.rand(batch_size, 1, device=feat_microscopic2.device) < self.modality_dropout_prob).float()\n",
    "        #         feat_microscopic2 = (1 - mask) * feat_microscopic2 + mask * self.placeholder_microscopic2.unsqueeze(0).expand(batch_size, -1)\n",
    "        # else:\n",
    "        #     feat_microscopic2 = self.placeholder_microscopic2.unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "        # if microscopic3 is not None:\n",
    "        #     feat_microscopic3 = self.encoder_microscopic3(microscopic3)\n",
    "        #     if training:\n",
    "        #         mask = (torch.rand(batch_size, 1, device=feat_microscopic3.device) < self.modality_dropout_prob).float()\n",
    "        #         feat_microscopic3 = (1 - mask) * feat_microscopic3 + mask * self.placeholder_microscopic3.unsqueeze(0).expand(batch_size, -1)\n",
    "        # else:\n",
    "        #     feat_microscopic3 = self.placeholder_microscopic3.unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "        # if microscopic4 is not None:\n",
    "        #     feat_microscopic4 = self.encoder_microscopic4(microscopic4)\n",
    "        #     if training:\n",
    "        #         mask = (torch.rand(batch_size, 1, device=feat_microscopic4.device) < self.modality_dropout_prob).float()\n",
    "        #         feat_microscopic4 = (1 - mask) * feat_microscopic4 + mask * self.placeholder_microscopic4.unsqueeze(0).expand(batch_size, -1)\n",
    "        # else:\n",
    "        #     feat_microscopic4 = self.placeholder_microscopic4.unsqueeze(0).expand(batch_size, -1)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #fused_features = torch.cat([feat_ultrasound, feat_mammogram1, feat_microscopic1], dim=1)\n",
    "        #output = self.fusion(fused_features)\n",
    "        if mammogram1 is None:\n",
    "            if microscopic1 is None:\n",
    "                output = feat_ultrasound\n",
    "                return output\n",
    "        # return feat_ultrasound, feat_mammogram1, feat_microscopic1\n",
    "        return feat_ultrasound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8a34484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.047685Z",
     "iopub.status.busy": "2025-04-08T09:20:48.047474Z",
     "iopub.status.idle": "2025-04-08T09:20:48.053351Z",
     "shell.execute_reply": "2025-04-08T09:20:48.052558Z"
    },
    "papermill": {
     "duration": 0.020346,
     "end_time": "2025-04-08T09:20:48.054445",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.034099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 68.552684 millions\n"
     ]
    }
   ],
   "source": [
    "vision_model = v_model()\n",
    "total_params = sum(p.numel() for p in vision_model.parameters())\n",
    "print(f\"Total parameters: {total_params/1000000} millions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1217856e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.081198Z",
     "iopub.status.busy": "2025-04-08T09:20:48.080982Z",
     "iopub.status.idle": "2025-04-08T09:20:48.085815Z",
     "shell.execute_reply": "2025-04-08T09:20:48.085173Z"
    },
    "papermill": {
     "duration": 0.019477,
     "end_time": "2025-04-08T09:20:48.086992",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.067515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class q_former(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(q_former,self).__init__()\n",
    "        self.slm = MiniBERTEncoder()\n",
    "        self.vision = v_model()\n",
    "        self.fused_model = ConvFusionClassifier()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        ultrasound=None,\n",
    "        mammogram1=None,\n",
    "        mammogram2=None,\n",
    "        microscopic1=None,\n",
    "        microscopic2=None,\n",
    "        microscopic3=None,\n",
    "        microscopic4=None,\n",
    "    ):\n",
    "        #out_slm, text_feature = self.slm(input_ids)  \n",
    "        text_feature = self.slm(input_ids)  \n",
    "\n",
    "        vision_output = self.vision(\n",
    "            ultrasound=ultrasound,\n",
    "            mammogram1=mammogram1,\n",
    "            mammogram2=mammogram2,\n",
    "            microscopic1=microscopic1,\n",
    "            microscopic2=microscopic2,\n",
    "            microscopic3=microscopic3,\n",
    "            microscopic4=microscopic4\n",
    "        )\n",
    "\n",
    "        if isinstance(vision_output, tuple):\n",
    "            # feat_ultrasound, feat_mammogram1, feat_microscopic1 = vision_output\n",
    "            feat_ultrasound = vision_output\n",
    "\n",
    "            # combined_vision = (feat_ultrasound + feat_mammogram1 + feat_microscopic1) / 3\n",
    "            vision_output = self.fused_model(feat_ultrasound, text_feature)\n",
    "            #return feat_ultrasound, out_slm\n",
    "            return vision_output\n",
    "        feat_ultrasound = vision_output\n",
    "        vision_output = self.fused_model(feat_ultrasound, text_feature)     \n",
    "        #return vision_output, out_slm\n",
    "        return vision_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ec77ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.113530Z",
     "iopub.status.busy": "2025-04-08T09:20:48.113329Z",
     "iopub.status.idle": "2025-04-08T09:20:48.429269Z",
     "shell.execute_reply": "2025-04-08T09:20:48.428546Z"
    },
    "papermill": {
     "duration": 0.33087,
     "end_time": "2025-04-08T09:20:48.430874",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.100004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = q_former()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "588aa31d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.457999Z",
     "iopub.status.busy": "2025-04-08T09:20:48.457746Z",
     "iopub.status.idle": "2025-04-08T09:20:48.461101Z",
     "shell.execute_reply": "2025-04-08T09:20:48.460483Z"
    },
    "papermill": {
     "duration": 0.017911,
     "end_time": "2025-04-08T09:20:48.462230",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.444319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def generate_dummy_data(batch_size, channels=3, height=224, width=224):\n",
    "#     ultrasound   = torch.randn(batch_size, channels, height, width, device=device)\n",
    "#     mammogram1    = torch.randn(batch_size, channels, height, width, device=device)\n",
    "#     mammogram2    = torch.randn(batch_size, channels, height, width, device=device)\n",
    "#     microscopic1  = torch.randn(batch_size, channels, height, width, device=device)\n",
    "#     microscopic2  = torch.randn(batch_size, channels, height, width, device=device)\n",
    "#     microscopic3  = torch.randn(batch_size, channels, height, width, device=device)\n",
    "#     microscopic4  = torch.randn(batch_size, channels, height, width, device=device)\n",
    "#     labels = torch.randint(0, 2, (batch_size,)) \n",
    "#     return ultrasound, mammogram1, mammogram2, microscopic1, microscopic2, microscopic3, microscopic4, labels\n",
    "# model = v_model()\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     def test_inference(us=None, mam1=None, mam2=None, mic1=None, mic2=None, mic3=None, mic4=None, description=\"\"):\n",
    "#         outputs = model(ultrasound=us, mammogram1=mam1, mammogram2=mam2, microscopic1=mic1, microscopic2=mic2, microscopic3=mic3, microscopic4=mic4, training=False)\n",
    "#         preds = torch.argmax(outputs, dim=1)\n",
    "#         print(f\"{description} -> Predictions: {preds.tolist()}\")\n",
    "#     us, mam1, mam2, mic1, mic2, mic3, mic4, _ = generate_dummy_data(batch_size_1)\n",
    "#     us, mam1, mam2, mic1, mic2, mic3, mic4, _ = generate_dummy_data(batch_size_1)\n",
    "#     test_inference(us=us, mam1=None, mam2=None, mic1=None, mic2=None, mic3=None, mic4=None, description=\"Only Ultrasound\")\n",
    "#     test_inference(us=None, mam1=mam1, mam2=mam2, mic1=None, mic2=None, mic3=None, mic4=None, description=\"Only Mammogram\")\n",
    "#     test_inference(us=None, mam1=None, mam2=None, mic1=mic1, mic2=mic2, mic3=mic3, mic4=mic4, description=\"Only Microscopic\")\n",
    "#     test_inference(us=us, mam1=mam1, mam2=mam2, mic1=None, mic2=None, mic3=None, mic4=None, description=\"Ultrasound & Mammogram\")\n",
    "#     test_inference(us=None, mam1=mam1, mam2=mam2, mic1=mic1, mic2=mic2, mic3=mic3, mic4=mic4, description=\"Mammogram & Microscopic\")\n",
    "#     test_inference(us=us, mam1=None, mam2=None, mic1=mic1, mic2=mic2, mic3=mic3, mic4=mic4, description=\"Ultrasound & Microscopic\")\n",
    "#     test_inference(us=us, mam1=mam1, mam2=mam2, mic1=mic1, mic2=mic2, mic3=mic3, mic4=mic4, description=\"All Modalities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a363ef",
   "metadata": {
    "papermill": {
     "duration": 0.012442,
     "end_time": "2025-04-08T09:20:48.487562",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.475120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Dataset class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7866f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.514313Z",
     "iopub.status.busy": "2025-04-08T09:20:48.514104Z",
     "iopub.status.idle": "2025-04-08T09:20:48.529717Z",
     "shell.execute_reply": "2025-04-08T09:20:48.528910Z"
    },
    "papermill": {
     "duration": 0.030356,
     "end_time": "2025-04-08T09:20:48.531070",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.500714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class base_dataset(Dataset):\n",
    "    def __init__(self, train, texts_in=None, texts_out=None, img_paths_1=None, img_paths_2=None, img_paths_3=None, img_paths_4=None, img_paths_5=None, img_paths_6=None, img_paths_7=None, labels=None):\n",
    "        self.train = train\n",
    "        self.img_size = 224\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        tokenizer.add_special_tokens({'pad_token': '[PAD]'}) \n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_in = texts_in\n",
    "        self.text_out = texts_out\n",
    "        self.img_paths_1 = img_paths_1\n",
    "        self.img_paths_2 = img_paths_2\n",
    "        self.img_paths_3 = img_paths_3\n",
    "        self.img_paths_4 = img_paths_4\n",
    "        self.img_paths_5 = img_paths_5\n",
    "        self.img_paths_6 = img_paths_6\n",
    "        self.img_paths_7 = img_paths_7\n",
    "        self.labels = labels\n",
    "        self.max_length = self.fittest_max_length(texts_in, texts_out)\n",
    "        self.transforms = None\n",
    "        if self.train == True:\n",
    "            self.transforms = A.Compose([\n",
    "                A.Resize(height=self.img_size,width=self.img_size),\n",
    "                A.RandomResizedCrop(height=self.img_size,width=self.img_size,scale=(0.9,1.0),p=0.5),\n",
    "                A.Rotate(limit=10,border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = A.Compose([\n",
    "                A.Resize(height=self.img_size,width=self.img_size),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths_1)\n",
    "            \n",
    "    def __getitem__(self,idx):\n",
    "        if self.train == True:\n",
    "            tokens_in = self.tokenizer.encode_plus(\n",
    "                self.text_in[idx],\n",
    "                return_tensors='pt',\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True\n",
    "            )\n",
    "            input_ids = tokens_in[\"input_ids\"].squeeze(0)\n",
    "            img_path1 = self.img_paths_1[idx]\n",
    "            img_path2 = self.img_paths_2[idx]\n",
    "            img_path3 = self.img_paths_3[idx]\n",
    "            img_path4 = self.img_paths_4[idx]\n",
    "            img_path5 = self.img_paths_5[idx]\n",
    "            img_path6 = self.img_paths_6[idx]\n",
    "            img_path7 = self.img_paths_7[idx]\n",
    "            image1 = Image.open(img_path1)\n",
    "            image2 = Image.open(img_path2)\n",
    "            image3 = Image.open(img_path3)\n",
    "            image4 = Image.open(img_path4)\n",
    "            image5 = Image.open(img_path5)\n",
    "            image6 = Image.open(img_path6)\n",
    "            image7 = Image.open(img_path7)\n",
    "            image1 = image1.convert('RGB')\n",
    "            image2 = image2.convert('RGB')\n",
    "            image3 = image3.convert('RGB')\n",
    "            image4 = image4.convert('RGB')\n",
    "            image5 = image5.convert('RGB')\n",
    "            image6 = image6.convert('RGB')\n",
    "            image7 = image7.convert('RGB')\n",
    "            image1 = np.array(image1,dtype=np.float32) / 255.0\n",
    "            image2 = np.array(image2,dtype=np.float32) / 255.0\n",
    "            image3 = np.array(image3,dtype=np.float32) / 255.0\n",
    "            image4 = np.array(image4,dtype=np.float32) / 255.0\n",
    "            image5 = np.array(image5,dtype=np.float32) / 255.0\n",
    "            image6 = np.array(image6,dtype=np.float32) / 255.0\n",
    "            image7 = np.array(image7,dtype=np.float32) / 255.0\n",
    "            augmentation1 = self.transforms(image=image1)\n",
    "            augmentation2 = self.transforms(image=image2)\n",
    "            augmentation3 = self.transforms(image=image3)\n",
    "            augmentation4 = self.transforms(image=image4)\n",
    "            augmentation5 = self.transforms(image=image5)\n",
    "            augmentation6 = self.transforms(image=image6)\n",
    "            augmentation7 = self.transforms(image=image7)\n",
    "            image1 = augmentation1['image']\n",
    "            image2 = augmentation2['image']\n",
    "            image3 = augmentation3['image']\n",
    "            image4 = augmentation4['image']\n",
    "            image5 = augmentation5['image']\n",
    "            image6 = augmentation6['image']\n",
    "            image7 = augmentation7['image']\n",
    "            label = self.labels[idx]\n",
    "            image_transformed = []\n",
    "\n",
    "            # Append images\n",
    "            image_transformed.append(image1)\n",
    "            image_transformed.append(image2)\n",
    "            image_transformed.append(image3)\n",
    "            image_transformed.append(image4)\n",
    "            image_transformed.append(image5)\n",
    "            image_transformed.append(image6)\n",
    "            image_transformed.append(image7)\n",
    "        # return image1, image2, image3, image4, image5, image6, image7, label\n",
    "        #     img_paths = [self.img_paths_1[idx], self.img_paths_2[idx], self.img_paths_3[idx], \n",
    "        #                  self.img_paths_4[idx], self.img_paths_5[idx], self.img_paths_6[idx], \n",
    "        #                  self.img_paths_7[idx]]\n",
    "    \n",
    "        #     images = []\n",
    "        #     for path in img_paths:\n",
    "        #         img = Image.open(path).convert('RGB')\n",
    "        #         img = np.array(img, dtype=np.float32) / 255.0\n",
    "        #         images.append(img)\n",
    "        #     augmented = self.transforms(image=images[0])\n",
    "        #     replay = augmented['replay']\n",
    "        #     images_transformed = [augmented['image']]\n",
    "        #     for i in range(1, len(images)):\n",
    "        #         aug = A.ReplayCompose.replay(replay, image=images[i])\n",
    "        #         images_transformed.append(aug['image'])\n",
    "        #     label = self.labels[idx]\n",
    "        else:\n",
    "            tokens_in = self.tokenizer.encode_plus(\n",
    "                self.text_in[idx],\n",
    "                return_tensors='pt',\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True\n",
    "            )\n",
    "            input_ids = tokens_in[\"input_ids\"].squeeze(0)\n",
    "            img_path = self.img_paths_1[idx]\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = np.array(image, dtype=np.float32) / 255.0\n",
    "            augmented = self.transforms(image=image)\n",
    "            images_transformed = augmented['image']\n",
    "            label = self.labels[idx]\n",
    "            return images_transformed, input_ids, label\n",
    "        return (*image_transformed, input_ids, label)\n",
    "        \n",
    "    def fittest_max_length(self, texts_in, texts_out):\n",
    "        max_lengths = []\n",
    "        \n",
    "        for label in df_in.columns:\n",
    "            max_len_in_col = df_in[label].astype(str).map(len).max()\n",
    "            max_lengths.append(max_len_in_col)\n",
    "        \n",
    "        for label in df_out.columns:\n",
    "            max_len_out_col = df_out[label].astype(str).map(len).max()\n",
    "            max_lengths.append(max_len_out_col)\n",
    "        \n",
    "        max_length = max(max_lengths)\n",
    "        \n",
    "        x = 2\n",
    "        while x < max_length:\n",
    "            x = x * 2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c28fdf21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.558027Z",
     "iopub.status.busy": "2025-04-08T09:20:48.557785Z",
     "iopub.status.idle": "2025-04-08T09:20:48.561058Z",
     "shell.execute_reply": "2025-04-08T09:20:48.560275Z"
    },
    "papermill": {
     "duration": 0.017964,
     "end_time": "2025-04-08T09:20:48.562190",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.544226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class base_dataset_valid(Dataset):\n",
    "#     def __init__(self, train, img_paths, labels):\n",
    "#         self.train = train\n",
    "#         self.img_size = 224\n",
    "#         self.img_paths = img_paths\n",
    "#         self.labels = labels\n",
    "#         self.transforms = None\n",
    "#         if self.train == True:\n",
    "#             self.transforms = A.Compose([\n",
    "#                 A.Resize(height=self.img_size,width=self.img_size),\n",
    "#                 A.RandomResizedCrop(height=self.img_size,width=self.img_size,scale=(0.9,1.0),p=0.5),\n",
    "#                 A.Rotate(limit=10,border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
    "#                 A.HorizontalFlip(p=0.5),\n",
    "#                 A.VerticalFlip(p=0.5),\n",
    "#                 ToTensorV2()\n",
    "#             ])\n",
    "#         else:\n",
    "#             self.transforms = A.Compose([\n",
    "#                 A.Resize(height=self.img_size,width=self.img_size),\n",
    "#                 ToTensorV2()\n",
    "#             ])\n",
    "            \n",
    "#     def __len__(self):\n",
    "#         return len(self.img_paths)\n",
    "            \n",
    "#     def __getitem__(self,idx):\n",
    "#         img_path = self.img_paths[idx]\n",
    "#         #img_name = os.path.basename(img_path)\n",
    "#         label = self.labels[idx]\n",
    "#         image = Image.open(img_path)\n",
    "#         image = image.convert('RGB')\n",
    "#         image = np.array(image,dtype=np.float32) / 255.0\n",
    "#         augmentation = self.transforms(image=image)\n",
    "#         image = augmentation['image']\n",
    "#         return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ee9d3",
   "metadata": {
    "papermill": {
     "duration": 0.012594,
     "end_time": "2025-04-08T09:20:48.587553",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.574959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Assistive function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d2dae0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.613812Z",
     "iopub.status.busy": "2025-04-08T09:20:48.613567Z",
     "iopub.status.idle": "2025-04-08T09:20:48.616603Z",
     "shell.execute_reply": "2025-04-08T09:20:48.616050Z"
    },
    "papermill": {
     "duration": 0.017271,
     "end_time": "2025-04-08T09:20:48.617636",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.600365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_patient_number(path):\n",
    "    match = re.search(r'Patient - Copy \\((\\d+)\\)', path)\n",
    "    return int(match.group(1)) if match else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6873563b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.643869Z",
     "iopub.status.busy": "2025-04-08T09:20:48.643616Z",
     "iopub.status.idle": "2025-04-08T09:20:48.647335Z",
     "shell.execute_reply": "2025-04-08T09:20:48.646776Z"
    },
    "papermill": {
     "duration": 0.017987,
     "end_time": "2025-04-08T09:20:48.648462",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.630475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137d195",
   "metadata": {
    "papermill": {
     "duration": 0.01377,
     "end_time": "2025-04-08T09:20:48.675034",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.661264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Loss funtions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71ec05ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.701345Z",
     "iopub.status.busy": "2025-04-08T09:20:48.701150Z",
     "iopub.status.idle": "2025-04-08T09:20:48.703996Z",
     "shell.execute_reply": "2025-04-08T09:20:48.703409Z"
    },
    "papermill": {
     "duration": 0.017284,
     "end_time": "2025-04-08T09:20:48.705091",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.687807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classification_loss1 = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf615f",
   "metadata": {
    "papermill": {
     "duration": 0.013747,
     "end_time": "2025-04-08T09:20:48.731563",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.717816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Validation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87ee28aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.758101Z",
     "iopub.status.busy": "2025-04-08T09:20:48.757893Z",
     "iopub.status.idle": "2025-04-08T09:20:48.764467Z",
     "shell.execute_reply": "2025-04-08T09:20:48.763919Z"
    },
    "papermill": {
     "duration": 0.021001,
     "end_time": "2025-04-08T09:20:48.765624",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.744623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validator(valid_loader,model,device):\n",
    "    model.eval()\n",
    "    eps = 1e-9\n",
    "    step = 0\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    sample = 0\n",
    "    total_samples = 0\n",
    "    classification_accuracy = 0\n",
    "    classification_precision = 0\n",
    "    classification_recall = 0\n",
    "    classification_specificity = 0\n",
    "    classification_f1 = 0\n",
    "    classification_mcc = 0\n",
    "    for idx, (images, input_ids, labels_list) in enumerate(valid_loader):\n",
    "        images = images.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        label_indices = [class_index[label] for label in labels_list]\n",
    "        labels = torch.tensor(label_indices, dtype = torch.long, device = device)\n",
    "        with torch.no_grad():\n",
    "            #prediction_labels, prediction_text = model(input_ids, images)\n",
    "            prediction_labels = model(input_ids, images)\n",
    "            _,prediction_labels = torch.max(prediction_labels,1)\n",
    "            total_samples +=labels.size(0)\n",
    "            tp += ((prediction_labels == 0) & (labels == 0)).sum().item()\n",
    "            fp += ((prediction_labels == 0) & (labels == 1)).sum().item()\n",
    "            fn += ((prediction_labels == 1) & (labels == 0)).sum().item()\n",
    "            tn += ((prediction_labels == 1) & (labels == 1)).sum().item()\n",
    "\n",
    "    classification_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    classification_precision = (tp + eps) / ((tp + fp) + eps)\n",
    "    classification_recall = (tp + eps)/ ((tp + fn) + eps)\n",
    "    classification_specificity = (tn + eps) / ((tn + fp) + eps)\n",
    "    classification_f1 = 2 * (classification_precision * classification_recall) / (classification_precision + classification_recall)\n",
    "    classification_mcc = ((tp * tn - fp * fn) + eps) / (math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) + eps)\n",
    "    return classification_accuracy, classification_precision, classification_recall, classification_specificity, classification_f1, classification_mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f985b4",
   "metadata": {
    "papermill": {
     "duration": 0.012673,
     "end_time": "2025-04-08T09:20:48.791794",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.779121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Trainer function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efc4e8f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.818300Z",
     "iopub.status.busy": "2025-04-08T09:20:48.818080Z",
     "iopub.status.idle": "2025-04-08T09:20:48.824198Z",
     "shell.execute_reply": "2025-04-08T09:20:48.823597Z"
    },
    "papermill": {
     "duration": 0.020768,
     "end_time": "2025-04-08T09:20:48.825372",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.804604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_function(train_loader, model, loss_function1, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    total_batches = len(train_loader)\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    device = device\n",
    "    end = time.time()\n",
    "    for idx, (images1, images2, images3, images4, images5, images6, images7, input_ids, label_list) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - end)\n",
    "        images1, images2, images3, images4, images5, images6, images7, input_ids = [x.to(device) for x in [images1, images2, images3, images4, images5, images6, images7, input_ids]]\n",
    "        label_indices = [class_index[label] for label in label_list]\n",
    "        labels = torch.tensor(label_indices, dtype = torch.long, device = device)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes = 2).float()\n",
    "        # prediction_labels_us, prediction_labels_mm, prediction_labels_hs, prediction_text = model(input_ids, images1, images2, images3, images4, images5, images6, images7)\n",
    "        prediction_labels_us = model(input_ids, images1, images2, images3, images4, images5, images6, images7)\n",
    "        class_loss1 = loss_function1(prediction_labels_us,labels_one_hot)\n",
    "        # class_loss2 = loss_function1(prediction_labels_mm,labels_one_hot)\n",
    "        # class_loss3 = loss_function1(prediction_labels_hs,labels_one_hot)\n",
    "        # class_loss4 = loss_function1(prediction_text,labels_one_hot)\n",
    "        loss =  class_loss1 #+ class_loss2 + class_loss3 + class_loss4\n",
    "        batch_size = images1.shape[0]\n",
    "        losses.update(loss.detach(), batch_size)\n",
    "        batch_time.update(time.time()- end)\n",
    "        end = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4ba77",
   "metadata": {
    "papermill": {
     "duration": 0.012948,
     "end_time": "2025-04-08T09:20:48.851287",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.838339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Data Loading**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1060d13a",
   "metadata": {
    "papermill": {
     "duration": 0.012629,
     "end_time": "2025-04-08T09:20:48.876771",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.864142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Text loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "622cb63f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:48.903475Z",
     "iopub.status.busy": "2025-04-08T09:20:48.903269Z",
     "iopub.status.idle": "2025-04-08T09:20:49.960923Z",
     "shell.execute_reply": "2025-04-08T09:20:49.959865Z"
    },
    "papermill": {
     "duration": 1.072881,
     "end_time": "2025-04-08T09:20:49.962530",
     "exception": false,
     "start_time": "2025-04-08T09:20:48.889649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "df_in = pd.read_excel('/kaggle/input/multi-modal-breast-lesion-dataset/Data_entry.xlsx', sheet_name='Sheet1')\n",
    "df_in = df_in.dropna(subset=['Pathology level\\nCNB'])\n",
    "df_in = df_in.reset_index(drop=True)\n",
    "df_in.columns = df_in.columns.str.replace('\\n', ' ', regex=True)\n",
    "df_in.columns = df_in.columns.str.strip()\n",
    "df_in = df_in.map(lambda x: x.replace('\\n', ' ') if isinstance(x, str) else x)\n",
    "df_in = df_in.fillna(0)\n",
    "df_in = df_in.map(lambda x: 0 if isinstance(x, str) and x.strip() == '-' else x)\n",
    "df_in.drop(['Sub-division','Recom(US)','BI-RADS (US)','Pathology level Surgical','Pathology level CNB','Radiology(US)','Radiology(MG)','BI-RAD (MG)','Recom(MG)','Skin Thickness','Duct','Fatty tissue','Muscles','Lesion Size','Lesion depth','Lesion Location','Breast density percentage'], axis=1, inplace=True)\n",
    "df_in = df_in.replace(r'\\t', ' ', regex=True)\n",
    "df_in = df_in.replace(r'definedac', 'defined', regex=True)\n",
    "df_in = df_in.replace(0, 'No Data Available')\n",
    "df_in = df_in.replace(r'y\\(s\\)', '', regex=True)\n",
    "#df_in = pd.concat([df_in] * 100, ignore_index=True)\n",
    "\n",
    "print(len(df_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a79eed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:49.991489Z",
     "iopub.status.busy": "2025-04-08T09:20:49.991031Z",
     "iopub.status.idle": "2025-04-08T09:20:50.011970Z",
     "shell.execute_reply": "2025-04-08T09:20:50.011235Z"
    },
    "papermill": {
     "duration": 0.036109,
     "end_time": "2025-04-08T09:20:50.013182",
     "exception": false,
     "start_time": "2025-04-08T09:20:49.977073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient No</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Personal History</th>\n",
       "      <th>Indication</th>\n",
       "      <th>Menopause</th>\n",
       "      <th>Calcification</th>\n",
       "      <th>Nipple retraction</th>\n",
       "      <th>Echoes</th>\n",
       "      <th>Border/Margin</th>\n",
       "      <th>Posterior acoustic  shadowing</th>\n",
       "      <th>Edge Shadow</th>\n",
       "      <th>Architectural  disruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient - Copy (1)</td>\n",
       "      <td>48</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>Diagnosed case of  carcinoma right breast</td>\n",
       "      <td>Surgical  menopause</td>\n",
       "      <td>Absent</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>Ill-defined</td>\n",
       "      <td>Present</td>\n",
       "      <td>Thick</td>\n",
       "      <td>Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patient - Copy (2)</td>\n",
       "      <td>54</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>Pain in right breast    H/O breasts  augmentat...</td>\n",
       "      <td>Surgical  menopause</td>\n",
       "      <td>Absent</td>\n",
       "      <td>No</td>\n",
       "      <td>Hypoechoic  with cystic changes</td>\n",
       "      <td>Well-defined</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Thin</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patient - Copy (3)</td>\n",
       "      <td>37</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>visit 5 times</td>\n",
       "      <td>Pain in both breasts H/O right breast lumpectomy</td>\n",
       "      <td>12.07.2024</td>\n",
       "      <td>Absent</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>Hypoechoic with  central  echogenic hilum</td>\n",
       "      <td>Well-defined</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Thin</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patient - Copy (4)</td>\n",
       "      <td>49</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>4  times</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>Wall micro calcifications</td>\n",
       "      <td>No</td>\n",
       "      <td>Thick walled dilated duct with wall micro calc...</td>\n",
       "      <td>ill-defined Absent Thin Absent</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>No Data Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patient - Copy (5)</td>\n",
       "      <td>40</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>1 visit</td>\n",
       "      <td>Pain and swelling in both axilla  Post mastect...</td>\n",
       "      <td>07.07.2024</td>\n",
       "      <td>Absent</td>\n",
       "      <td>No</td>\n",
       "      <td>Hypoechoic with central  echogenic hilum</td>\n",
       "      <td>Well-defined</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Thin</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Patient No  AGE     Family History   Personal History  \\\n",
       "0  Patient - Copy (1)   48  No Data Available  No Data Available   \n",
       "1  Patient - Copy (2)  54   No Data Available  No Data Available   \n",
       "2  Patient - Copy (3)  37   No Data Available      visit 5 times   \n",
       "3  Patient - Copy (4)  49   No Data Available           4  times   \n",
       "4  Patient - Copy (5)  40   No Data Available            1 visit   \n",
       "\n",
       "                                          Indication            Menopause  \\\n",
       "0          Diagnosed case of  carcinoma right breast  Surgical  menopause   \n",
       "1  Pain in right breast    H/O breasts  augmentat...  Surgical  menopause   \n",
       "2  Pain in both breasts H/O right breast lumpectomy            12.07.2024   \n",
       "3                                          Follow up    No Data Available   \n",
       "4  Pain and swelling in both axilla  Post mastect...           07.07.2024   \n",
       "\n",
       "               Calcification  Nipple retraction  \\\n",
       "0                     Absent  No Data Available   \n",
       "1                     Absent                 No   \n",
       "2                     Absent  No Data Available   \n",
       "3  Wall micro calcifications                 No   \n",
       "4                     Absent                 No   \n",
       "\n",
       "                                              Echoes  \\\n",
       "0                                  No Data Available   \n",
       "1                   Hypoechoic  with cystic changes    \n",
       "2          Hypoechoic with  central  echogenic hilum   \n",
       "3  Thick walled dilated duct with wall micro calc...   \n",
       "4           Hypoechoic with central  echogenic hilum   \n",
       "\n",
       "                    Border/Margin Posterior acoustic  shadowing  \\\n",
       "0                     Ill-defined                       Present   \n",
       "1                    Well-defined                        Absent   \n",
       "2                    Well-defined                        Absent   \n",
       "3  ill-defined Absent Thin Absent             No Data Available   \n",
       "4                    Well-defined                        Absent   \n",
       "\n",
       "         Edge Shadow Architectural  disruption  \n",
       "0              Thick                   Present  \n",
       "1               Thin                    Absent  \n",
       "2               Thin                    Absent  \n",
       "3  No Data Available         No Data Available  \n",
       "4               Thin                    Absent  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af2dec4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.040303Z",
     "iopub.status.busy": "2025-04-08T09:20:50.040082Z",
     "iopub.status.idle": "2025-04-08T09:20:50.065712Z",
     "shell.execute_reply": "2025-04-08T09:20:50.065051Z"
    },
    "papermill": {
     "duration": 0.04034,
     "end_time": "2025-04-08T09:20:50.066886",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.026546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient No</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Personal History</th>\n",
       "      <th>Indication</th>\n",
       "      <th>Menopause</th>\n",
       "      <th>Calcification</th>\n",
       "      <th>Nipple retraction</th>\n",
       "      <th>Echoes</th>\n",
       "      <th>Border/Margin</th>\n",
       "      <th>Posterior acoustic  shadowing</th>\n",
       "      <th>Edge Shadow</th>\n",
       "      <th>Architectural  disruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Patient - Copy (1)</td>\n",
       "      <td>40</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>Left breast lump</td>\n",
       "      <td>No Data Available</td>\n",
       "      <td>Absent</td>\n",
       "      <td>No</td>\n",
       "      <td>Hypoechoic</td>\n",
       "      <td>Ill-defined</td>\n",
       "      <td>Absent</td>\n",
       "      <td>Thin</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Patient No  AGE     Family History   Personal History  \\\n",
       "count                   27   27                 27                 27   \n",
       "unique                  27   23                  5                  4   \n",
       "top     Patient - Copy (1)  40   No Data Available  No Data Available   \n",
       "freq                     1    2                 23                 24   \n",
       "\n",
       "              Indication          Menopause Calcification Nipple retraction  \\\n",
       "count                 27                 27            27                27   \n",
       "unique                22                 15             8                 3   \n",
       "top     Left breast lump  No Data Available        Absent                No   \n",
       "freq                   3                 10            17                14   \n",
       "\n",
       "            Echoes Border/Margin Posterior acoustic  shadowing Edge Shadow  \\\n",
       "count           27            27                            27          27   \n",
       "unique          16             6                             4           3   \n",
       "top     Hypoechoic   Ill-defined                        Absent        Thin   \n",
       "freq             9             9                            15          19   \n",
       "\n",
       "       Architectural  disruption  \n",
       "count                         27  \n",
       "unique                         4  \n",
       "top                       Absent  \n",
       "freq                          15  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a433b9c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.094250Z",
     "iopub.status.busy": "2025-04-08T09:20:50.094042Z",
     "iopub.status.idle": "2025-04-08T09:20:50.397178Z",
     "shell.execute_reply": "2025-04-08T09:20:50.396160Z"
    },
    "papermill": {
     "duration": 0.31833,
     "end_time": "2025-04-08T09:20:50.398534",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.080204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "df_out = pd.read_excel('/kaggle/input/multi-modal-breast-lesion-dataset/Data_entry.xlsx', sheet_name='Sheet1')\n",
    "df_out = df_out.dropna(subset=['Pathology level\\nCNB'])\n",
    "df_out = df_out.reset_index(drop=True)\n",
    "df_out.columns = df_out.columns.str.replace('\\n', ' ', regex=True)\n",
    "df_out.columns = df_out.columns.str.strip()\n",
    "df_out = df_out.map(lambda x: x.replace('\\n', ' ') if isinstance(x, str) else x)\n",
    "df_out = df_out.fillna(0)\n",
    "df_out = df_out.map(lambda x: 0 if isinstance(x, str) and x.strip() == '-' else x)\n",
    "df_out = df_out.replace(r'\\t', ' ', regex=True)\n",
    "df_out = df_out.replace(r'definedac', 'defined', regex=True)\n",
    "df_out = df_out.replace(0, 'No Data Available')\n",
    "df_out = df_out.replace(r'y\\(s\\)', '', regex=True)\n",
    "df_out.drop(['Recom(US)','BI-RADS (US)','Radiology(US)','Sub-division','Patient No','Radiology(MG)','Muscles','Fatty tissue','Duct','Skin Thickness','Lesion Location','Lesion depth','Lesion Size','Breast density percentage','Recom(MG)','BI-RAD (MG)','Pathology level Surgical','Architectural  disruption','Posterior acoustic  shadowing','AGE','Family History','Personal History','Indication','Menopause','Calcification','Nipple retraction','Echoes','Border/Margin','Edge Shadow'], axis=1, inplace=True)\n",
    "#df_out = pd.concat([df_out] * 100, ignore_index=True)\n",
    "print(len(df_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbac7904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.426612Z",
     "iopub.status.busy": "2025-04-08T09:20:50.426376Z",
     "iopub.status.idle": "2025-04-08T09:20:50.432514Z",
     "shell.execute_reply": "2025-04-08T09:20:50.431806Z"
    },
    "papermill": {
     "duration": 0.021339,
     "end_time": "2025-04-08T09:20:50.433698",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.412359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pathology level CNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pathology level CNB\n",
       "0           Malignant\n",
       "1              Benign\n",
       "2              Benign\n",
       "3              Benign\n",
       "4              Benign"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2326702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.462023Z",
     "iopub.status.busy": "2025-04-08T09:20:50.461805Z",
     "iopub.status.idle": "2025-04-08T09:20:50.469521Z",
     "shell.execute_reply": "2025-04-08T09:20:50.468557Z"
    },
    "papermill": {
     "duration": 0.02324,
     "end_time": "2025-04-08T09:20:50.470916",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.447676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pathology level CNB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pathology level CNB\n",
       "count                   27\n",
       "unique                   2\n",
       "top                 Benign\n",
       "freq                    18"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a89a71e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.499382Z",
     "iopub.status.busy": "2025-04-08T09:20:50.499182Z",
     "iopub.status.idle": "2025-04-08T09:20:50.506458Z",
     "shell.execute_reply": "2025-04-08T09:20:50.505749Z"
    },
    "papermill": {
     "duration": 0.022421,
     "end_time": "2025-04-08T09:20:50.507605",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.485184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['Patient No: Patient - Copy (1) , AGE: 48 , Family History: No Data Available , Personal History: No Data Available , Indication: Diagnosed case of  carcinoma right breast , Menopause: Surgical  menopause , Calcification: Absent , Nipple retraction: No Data Available , Echoes: No Data Available , Border/Margin: Ill-defined , Posterior acoustic  shadowing: Present , Edge Shadow: Thick , Architectural  disruption: Present', 'Patient No: Patient - Copy (2) , AGE: 54  , Family History: No Data Available , Personal History: No Data Available , Indication: Pain in right breast    H/O breasts  augmentation– 2010. , Menopause: Surgical  menopause , Calcification: Absent , Nipple retraction: No , Echoes: Hypoechoic  with cystic changes  , Border/Margin:  Well-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (3) , AGE: 37  , Family History: No Data Available , Personal History: visit 5 times , Indication: Pain in both breasts H/O right breast lumpectomy  , Menopause: 12.07.2024 , Calcification: Absent , Nipple retraction: No Data Available , Echoes: Hypoechoic with  central  echogenic hilum , Border/Margin: Well-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (4) , AGE: 49  , Family History: No Data Available , Personal History: 4  times , Indication: Follow up , Menopause: No Data Available , Calcification: Wall micro calcifications , Nipple retraction: No , Echoes: Thick walled dilated duct with wall micro calcifications , Border/Margin: ill-defined Absent Thin Absent , Posterior acoustic  shadowing: No Data Available , Edge Shadow: No Data Available , Architectural  disruption: No Data Available', 'Patient No: Patient - Copy (5) , AGE: 40  , Family History: No Data Available , Personal History: 1 visit , Indication: Pain and swelling in both axilla  Post mastectomy state and reconstruction of carcinoma of right breast , Menopause: 07.07.2024 , Calcification: Absent , Nipple retraction: No , Echoes: Hypoechoic with central  echogenic hilum , Border/Margin: Well-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (6) , AGE: 35  , Family History: No Data Available , Personal History: No Data Available , Indication: Left breast lump , Menopause: 28.06.2024 , Calcification: Extensive micro calcifications , Nipple retraction: No Data Available , Echoes: Hypoechoic , Border/Margin: Ill-defined , Posterior acoustic  shadowing: Present , Edge Shadow: Thick , Architectural  disruption: Present', 'Patient No: Patient - Copy (7) , AGE: 40  , Family History: No Data Available , Personal History: No Data Available , Indication: Pain in right breast. , Menopause: Menopause , Calcification: Absent , Nipple retraction: No , Echoes: Cluster of micro cysts , Border/Margin: Ill-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (8) , AGE: 36 , Family History: No Data Available , Personal History: No Data Available , Indication: Pain in right breast. , Menopause: 02.06.2024 , Calcification: Absent , Nipple retraction: No Data Available , Echoes: Mixed echogenic , Border/Margin: Well-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (9) , AGE: 28 , Family History: No Data Available , Personal History: No Data Available , Indication: Pain & lump in left breast. , Menopause: 04.06.2024 , Calcification: Absent , Nipple retraction: No Data Available , Echoes: Thick walled anechoic area  containing low level  echoes within it , Border/Margin: Ill-defined , Posterior acoustic  shadowing: Absent  , Edge Shadow: Thin , Architectural  disruption: Absent ', 'Patient No: Patient - Copy (10) , AGE: 39 , Family History: Mother and Sister had breast cancer , Personal History: No Data Available , Indication: Pain and lumpiness in right breast , Menopause: 14.10.2024 , Calcification: Absent , Nipple retraction: No , Echoes: Hypoechoic , Border/Margin: Well-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (11) , AGE: 38 , Family History: No Data Available , Personal History: No Data Available , Indication: Left breast lump and left nipple discharge , Menopause: 25.10.2024  , Calcification: Absent , Nipple retraction: Yes , Echoes: Hypoechoic  , Border/Margin: Ill-defined , Posterior acoustic  shadowing: Absent  , Edge Shadow: Thin , Architectural  disruption: Absent ', 'Patient No: Patient - Copy (12) , AGE: 50 , Family History: No Data Available , Personal History: No Data Available , Indication: Right nipple bloody discharge  , Menopause: No Data Available , Calcification: Absent , Nipple retraction: Yes , Echoes: Hypoechoic  , Border/Margin: Ill-defined , Posterior acoustic  shadowing: Absent  , Edge Shadow: Thin , Architectural  disruption: Absent ', 'Patient No: Patient - Copy (13) , AGE: No Data Available , Family History: No Data Available , Personal History: No Data Available , Indication: lump in left breast. , Menopause: 10.11.2024 , Calcification: Extensive  microcalcifications , Nipple retraction: No Data Available , Echoes: Hypoechoic , Border/Margin: Ill-defined , Posterior acoustic  shadowing: Present , Edge Shadow: Thick , Architectural  disruption: Present', 'Patient No: Patient - Copy (14) , AGE: 45 , Family History: No Data Available , Personal History: No Data Available , Indication: Left breast lump H/O I&D of left breast abscess and excision of left breast sebaceous cyst , Menopause: Drug induced  amenorrhea , Calcification: Macro calcifications , Nipple retraction: No Data Available , Echoes: Mixed echogenic  predominantly hyperechoic , Border/Margin: Ill-defined , Posterior acoustic  shadowing: Absent  , Edge Shadow: Thin , Architectural  disruption: Absent ', 'Patient No: Patient - Copy (15) , AGE: 63 , Family History: No Data Available , Personal History: No Data Available , Indication: No Data Available , Menopause: Menopause , Calcification: Absent , Nipple retraction: No , Echoes: Hyperechoic with cystic changes within it , Border/Margin: Ill-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (16) , AGE: No Data Available , Family History: No Data Available , Personal History: No Data Available , Indication: No Data Available , Menopause: No Data Available , Calcification: No Data Available , Nipple retraction: No Data Available , Echoes: No Data Available , Border/Margin: No Data Available , Posterior acoustic  shadowing: No Data Available , Edge Shadow: No Data Available , Architectural  disruption: No Data Available', 'Patient No: Patient - Copy (17) , AGE: 56 , Family History: No Data Available , Personal History: No Data Available , Indication: Recurrent lump  in left breast , Menopause: Surgical menopause , Calcification: Cluster of micro  calcifications , Nipple retraction: No Data Available , Echoes: Complex solid  cystic mass , Border/Margin: Well-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (18) , AGE: 45 , Family History: Mother Had Breast Cancer , Personal History: No Data Available , Indication: Pain and lump  in right axilla , Menopause: Menopause , Calcification: Micro calcifications , Nipple retraction: No , Echoes: Hypoechoic , Border/Margin: Well-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (19) , AGE: 63 , Family History: No Data Available , Personal History: No Data Available , Indication: Pain and lump in right breast  , Menopause: No Data Available , Calcification: Absent , Nipple retraction: No , Echoes: Hypoechoic  , Border/Margin: Well-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (20) , AGE: 29 , Family History: No Data Available , Personal History: No Data Available , Indication: Left breast lump , Menopause: 15.11.2024 , Calcification: Micro calcifications , Nipple retraction: No , Echoes: Hypoechoic , Border/Margin: ill-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (21) , AGE: 55 , Family History: sister has breast cancer , Personal History: No Data Available , Indication: Pain in both breasts and axilla. , Menopause: Surgical Menopause , Calcification: Absent , Nipple retraction: No Data Available , Echoes: Cluster of microcysts   , Border/Margin: ill-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (22) , AGE: 54 , Family History: No Data Available , Personal History: No Data Available , Indication: breast lump and pus discharge from lump. Pain in left breast.  , Menopause: No Data Available , Calcification: Absent , Nipple retraction: No , Echoes: Cluster of microcysts  , Border/Margin: ill-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (23) , AGE: 72 , Family History: No Data Available , Personal History: No Data Available , Indication: Right breast lump  , Menopause: No Data Available , Calcification: Absent , Nipple retraction: Yes , Echoes: Hypoechoic , Border/Margin: ill-defined , Posterior acoustic  shadowing: Present , Edge Shadow: Thick , Architectural  disruption: Present', 'Patient No: Patient - Copy (24) , AGE: 69 , Family History: No Data Available , Personal History: No Data Available , Indication: Left breast lump , Menopause: No Data Available , Calcification: Micro calcifications , Nipple retraction: No , Echoes: Hypoechoic , Border/Margin: ill-defined , Posterior acoustic  shadowing: Present , Edge Shadow: Thick , Architectural  disruption: Present', 'Patient No: Patient - Copy (25) , AGE: 40 , Family History: No Data Available , Personal History: No Data Available , Indication: Right breast lump , Menopause: No Data Available , Calcification: Micro calcifications , Nipple retraction: No , Echoes: Hypoechoic , Border/Margin: ill-defined , Posterior acoustic  shadowing: Present , Edge Shadow: Thick , Architectural  disruption: Present', 'Patient No: Patient - Copy (26) , AGE: 35 , Family History: Parental Aunt have , Personal History: No Data Available , Indication: Right breast lump  , Menopause: No Data Available , Calcification: Absent , Nipple retraction: No , Echoes: Anechoic area , Border/Margin: Well-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent', 'Patient No: Patient - Copy (27) , AGE: 42 , Family History: No Data Available , Personal History: No Data Available , Indication: lump breast lump  , Menopause: No Data Available , Calcification: Absent , Nipple retraction: No , Echoes: Hypoechoic , Border/Margin: Well-defined , Posterior acoustic  shadowing: Absent , Edge Shadow: Thin , Architectural  disruption: Absent']\n"
     ]
    }
   ],
   "source": [
    "input_labels = df_in.columns.tolist()\n",
    "all_text_in = [\" , \".join(f\"{col}: {row[col]}\" for col in input_labels) for _, row in df_in.iterrows()]\n",
    "all_text_in = sorted(all_text_in, key=extract_patient_number)\n",
    "print(len(all_text_in))\n",
    "print(all_text_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4cb4562b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.535806Z",
     "iopub.status.busy": "2025-04-08T09:20:50.535557Z",
     "iopub.status.idle": "2025-04-08T09:20:50.541471Z",
     "shell.execute_reply": "2025-04-08T09:20:50.540663Z"
    },
    "papermill": {
     "duration": 0.021242,
     "end_time": "2025-04-08T09:20:50.542724",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.521482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['Pathology level CNB: Malignant', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Malignant', 'Pathology level CNB: Malignant', 'Pathology level CNB: Malignant', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Malignant', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Malignant', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign', 'Pathology level CNB: Malignant', 'Pathology level CNB: Malignant', 'Pathology level CNB: Malignant', 'Pathology level CNB: Benign', 'Pathology level CNB: Benign']\n"
     ]
    }
   ],
   "source": [
    "output_labels = df_out.columns.tolist()\n",
    "text_out = [\" , \".join(f\"{col}: {row[col]}\" for col in output_labels) for _, row in df_out.iterrows()]\n",
    "text_out = sorted(text_out, key=extract_patient_number)\n",
    "print(len(text_out))\n",
    "print(text_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b64be8",
   "metadata": {
    "papermill": {
     "duration": 0.013446,
     "end_time": "2025-04-08T09:20:50.569854",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.556408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Image loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b0dbc51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.597966Z",
     "iopub.status.busy": "2025-04-08T09:20:50.597758Z",
     "iopub.status.idle": "2025-04-08T09:20:50.613869Z",
     "shell.execute_reply": "2025-04-08T09:20:50.613010Z"
    },
    "papermill": {
     "duration": 0.031601,
     "end_time": "2025-04-08T09:20:50.615209",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.583608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Malignant/Patient - Copy (1).jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (2).jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (3).jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (4).jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (5).jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (6)_2 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (7)_1 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (8)_3 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (9)_6 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (10)_14 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Malignant/Patient - Copy (11)_4 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Malignant/Patient - Copy (12)_4 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Malignant/Patient - Copy (13)_5 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (14)_2 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (15)_2 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (16)_3 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Malignant/Patient - Copy (17)_9 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (18)_5 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (19)_4 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Malignant/Patient - Copy (20)_2 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (21)_1 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (22)_2 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Malignant/Patient - Copy (23)_3 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Malignant/Patient - Copy (24)_3 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Malignant/Patient - Copy (25)_3 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (26)_5 - Copy.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign/Patient - Copy (27)_3 - Copy.jpg']\n"
     ]
    }
   ],
   "source": [
    "all_us_img_paths = []\n",
    "\n",
    "temp_us_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Benign'\n",
    "temp_us_img_paths = [os.path.join(temp_us_img_folder,i) for i in os.listdir(temp_us_img_folder)]\n",
    "all_us_img_paths = all_us_img_paths + temp_us_img_paths \n",
    "\n",
    "temp_us_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Ultrasound/Malignant'\n",
    "temp_us_img_paths = [os.path.join(temp_us_img_folder,i) for i in os.listdir(temp_us_img_folder)]\n",
    "all_us_img_paths = all_us_img_paths + temp_us_img_paths \n",
    "\n",
    "all_us_img_paths.sort()\n",
    "all_us_img_paths = sorted(all_us_img_paths, key=extract_patient_number)\n",
    "\n",
    "print(len(all_us_img_paths))\n",
    "print(all_us_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef0212e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.643601Z",
     "iopub.status.busy": "2025-04-08T09:20:50.643402Z",
     "iopub.status.idle": "2025-04-08T09:20:50.674574Z",
     "shell.execute_reply": "2025-04-08T09:20:50.673721Z"
    },
    "papermill": {
     "duration": 0.046824,
     "end_time": "2025-04-08T09:20:50.675865",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.629041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/cc_view/Patient - Copy (1)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (2)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (3)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (4)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (5)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (6)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (7)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (8)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (9)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (10)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/cc_view/Patient - Copy (11)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/cc_view/Patient - Copy (12)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/cc_view/Patient - Copy (13)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (14)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (15)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (16)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/cc_view/Patient - Copy (17)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (18)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (19)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/cc_view/Patient - Copy (20)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (21)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (22)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/cc_view/Patient - Copy (23)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/cc_view/Patient - Copy (24)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/cc_view/Patient - Copy (25)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (26)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view/Patient - Copy (27)_2.jpg']\n"
     ]
    }
   ],
   "source": [
    "all_mm1_img_paths = []\n",
    "\n",
    "temp_mm1_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/cc_view'\n",
    "temp_mm1_img_paths = [os.path.join(temp_mm1_img_folder,i) for i in os.listdir(temp_mm1_img_folder)]\n",
    "all_mm1_img_paths = all_mm1_img_paths + temp_mm1_img_paths \n",
    "\n",
    "temp_mm1_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/cc_view'\n",
    "temp_mm1_img_paths = [os.path.join(temp_mm1_img_folder,i) for i in os.listdir(temp_mm1_img_folder)]\n",
    "all_mm1_img_paths = all_mm1_img_paths + temp_mm1_img_paths \n",
    "\n",
    "all_mm1_img_paths.sort()\n",
    "all_mm1_img_paths = sorted(all_mm1_img_paths, key=extract_patient_number)\n",
    "\n",
    "print(len(all_mm1_img_paths))\n",
    "print(all_mm1_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fbacef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.705875Z",
     "iopub.status.busy": "2025-04-08T09:20:50.705615Z",
     "iopub.status.idle": "2025-04-08T09:20:50.719549Z",
     "shell.execute_reply": "2025-04-08T09:20:50.718786Z"
    },
    "papermill": {
     "duration": 0.029853,
     "end_time": "2025-04-08T09:20:50.720875",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.691022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/mlo_view/Patient - Copy (1)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (2)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (3)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (4)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (5)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (6)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (7)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (8)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (9)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (10)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/mlo_view/Patient - Copy (11)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/mlo_view/Patient - Copy (12)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/mlo_view/Patient - Copy (13)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (14)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (15)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (16)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/mlo_view/Patient - Copy (17)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (18)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (19)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/mlo_view/Patient - Copy (20)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (21)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (22)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/mlo_view/Patient - Copy (23)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/mlo_view/Patient - Copy (24)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/mlo_view/Patient - Copy (25)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (26)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view/Patient - Copy (27)_4.jpg']\n"
     ]
    }
   ],
   "source": [
    "all_mm2_img_paths = []\n",
    "\n",
    "temp_mm2_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Benign/mlo_view'\n",
    "temp_mm2_img_paths = [os.path.join(temp_mm2_img_folder,i) for i in os.listdir(temp_mm2_img_folder)]\n",
    "all_mm2_img_paths = all_mm2_img_paths + temp_mm2_img_paths \n",
    "\n",
    "temp_mm2_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Mammogram/Malignant/mlo_view'\n",
    "temp_mm2_img_paths = [os.path.join(temp_mm2_img_folder,i) for i in os.listdir(temp_mm2_img_folder)]\n",
    "all_mm2_img_paths = all_mm2_img_paths + temp_mm2_img_paths \n",
    "\n",
    "all_mm2_img_paths.sort()\n",
    "all_mm2_img_paths = sorted(all_mm2_img_paths, key=extract_patient_number)\n",
    "\n",
    "print(len(all_mm2_img_paths))\n",
    "print(all_mm2_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46345c0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.750287Z",
     "iopub.status.busy": "2025-04-08T09:20:50.750088Z",
     "iopub.status.idle": "2025-04-08T09:20:50.767749Z",
     "shell.execute_reply": "2025-04-08T09:20:50.766929Z"
    },
    "papermill": {
     "duration": 0.033808,
     "end_time": "2025-04-08T09:20:50.769013",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.735205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_1/Patient - Copy (1)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (2)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (3)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (4)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (5)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (6)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (7)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (8)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (9)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (10)_1.JPG', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_1/Patient - Copy (11)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_1/Patient - Copy (12)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_1/Patient - Copy (13)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (14)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (15)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (16)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_1/Patient - Copy (17)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (18)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (19)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_1/Patient - Copy (20)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (21)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (22)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_1/Patient - Copy (23)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_1/Patient - Copy (24)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_1/Patient - Copy (25)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (26)_1.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1/Patient - Copy (27)_1.JPG']\n"
     ]
    }
   ],
   "source": [
    "all_hs1_img_paths = []\n",
    "\n",
    "temp_hs1_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_1'\n",
    "temp_hs1_img_paths = [os.path.join(temp_hs1_img_folder,i) for i in os.listdir(temp_hs1_img_folder)]\n",
    "all_hs1_img_paths = all_hs1_img_paths + temp_hs1_img_paths \n",
    "\n",
    "temp_hs1_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_1'\n",
    "temp_hs1_img_paths = [os.path.join(temp_hs1_img_folder,i) for i in os.listdir(temp_hs1_img_folder)]\n",
    "all_hs1_img_paths = all_hs1_img_paths + temp_hs1_img_paths \n",
    "\n",
    "all_hs1_img_paths.sort()\n",
    "all_hs1_img_paths = sorted(all_hs1_img_paths, key=extract_patient_number)\n",
    "\n",
    "print(len(all_hs1_img_paths))\n",
    "print(all_hs1_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f47a452d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.798185Z",
     "iopub.status.busy": "2025-04-08T09:20:50.797983Z",
     "iopub.status.idle": "2025-04-08T09:20:50.809792Z",
     "shell.execute_reply": "2025-04-08T09:20:50.808943Z"
    },
    "papermill": {
     "duration": 0.027961,
     "end_time": "2025-04-08T09:20:50.811084",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.783123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_2/Patient - Copy (1)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (2)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (3)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (4)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (5)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (6)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (7)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (8)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (9)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (10)_2.JPG', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_2/Patient - Copy (11)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_2/Patient - Copy (12)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_2/Patient - Copy (13)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (14)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (15)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (16)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_2/Patient - Copy (17)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (18)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (19)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_2/Patient - Copy (20)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (21)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (22)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_2/Patient - Copy (23)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_2/Patient - Copy (24)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_2/Patient - Copy (25)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (26)_2.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2/Patient - Copy (27)_2.JPG']\n"
     ]
    }
   ],
   "source": [
    "all_hs2_img_paths = []\n",
    "\n",
    "temp_hs2_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_2'\n",
    "temp_hs2_img_paths = [os.path.join(temp_hs2_img_folder,i) for i in os.listdir(temp_hs2_img_folder)]\n",
    "all_hs2_img_paths = all_hs2_img_paths + temp_hs2_img_paths \n",
    "\n",
    "temp_hs2_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_2'\n",
    "temp_hs2_img_paths = [os.path.join(temp_hs2_img_folder,i) for i in os.listdir(temp_hs2_img_folder)]\n",
    "all_hs2_img_paths = all_hs2_img_paths + temp_hs2_img_paths \n",
    "\n",
    "all_hs2_img_paths.sort()\n",
    "all_hs2_img_paths = sorted(all_hs2_img_paths, key=extract_patient_number)\n",
    "\n",
    "print(len(all_hs2_img_paths))\n",
    "print(all_hs2_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "647102e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.841785Z",
     "iopub.status.busy": "2025-04-08T09:20:50.841534Z",
     "iopub.status.idle": "2025-04-08T09:20:50.868170Z",
     "shell.execute_reply": "2025-04-08T09:20:50.867485Z"
    },
    "papermill": {
     "duration": 0.043705,
     "end_time": "2025-04-08T09:20:50.869362",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.825657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_3/Patient - Copy (1)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (2)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (3)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (4)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (5)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (6)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (7)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (8)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (9)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (10)_3.JPG', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_3/Patient - Copy (11)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_3/Patient - Copy (12)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_3/Patient - Copy (13)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (14)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (15)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (16)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_3/Patient - Copy (17)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (18)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (19)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_3/Patient - Copy (20)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (21)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (22)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_3/Patient - Copy (23)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_3/Patient - Copy (24)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_3/Patient - Copy (25)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (26)_3.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3/Patient - Copy (27)_3.JPG']\n"
     ]
    }
   ],
   "source": [
    "all_hs3_img_paths = []\n",
    "\n",
    "temp_hs3_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_3'\n",
    "temp_hs3_img_paths = [os.path.join(temp_hs3_img_folder,i) for i in os.listdir(temp_hs3_img_folder)]\n",
    "all_hs3_img_paths = all_hs3_img_paths + temp_hs3_img_paths \n",
    "\n",
    "temp_hs3_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_3'\n",
    "temp_hs3_img_paths = [os.path.join(temp_hs3_img_folder,i) for i in os.listdir(temp_hs3_img_folder)]\n",
    "all_hs3_img_paths = all_hs3_img_paths + temp_hs3_img_paths \n",
    "\n",
    "all_hs3_img_paths.sort()\n",
    "all_hs3_img_paths = sorted(all_hs3_img_paths, key=extract_patient_number)\n",
    "\n",
    "print(len(all_hs3_img_paths))\n",
    "print(all_hs3_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7adf1df1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.898269Z",
     "iopub.status.busy": "2025-04-08T09:20:50.898060Z",
     "iopub.status.idle": "2025-04-08T09:20:50.909221Z",
     "shell.execute_reply": "2025-04-08T09:20:50.908569Z"
    },
    "papermill": {
     "duration": 0.026848,
     "end_time": "2025-04-08T09:20:50.910324",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.883476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "['/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_4/Patient - Copy (1)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (2)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (3)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (4)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (5)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (6)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (7)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (8)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (9)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (10)_4.JPG', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_4/Patient - Copy (11)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_4/Patient - Copy (12)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_4/Patient - Copy (13)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (14)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (15)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (16)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_4/Patient - Copy (17)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (18)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (19)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_4/Patient - Copy (20)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (21)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (22)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_4/Patient - Copy (23)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_4/Patient - Copy (24)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_4/Patient - Copy (25)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (26)_4.jpg', '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4/Patient - Copy (27)_4.JPG']\n"
     ]
    }
   ],
   "source": [
    "all_hs4_img_paths = []\n",
    "\n",
    "temp_hs4_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Benign/zoom_view_4'\n",
    "temp_hs4_img_paths = [os.path.join(temp_hs4_img_folder,i) for i in os.listdir(temp_hs4_img_folder)]\n",
    "all_hs4_img_paths = all_hs4_img_paths + temp_hs4_img_paths \n",
    "\n",
    "temp_hs4_img_folder = '/kaggle/input/multi-modal-breast-lesion-dataset/Final_DATASET_v2/Final_DATASET_v2/Histopathology/Malignant/zoom_view_4'\n",
    "temp_hs4_img_paths = [os.path.join(temp_hs4_img_folder,i) for i in os.listdir(temp_hs4_img_folder)]\n",
    "all_hs4_img_paths = all_hs4_img_paths + temp_hs4_img_paths \n",
    "\n",
    "all_hs4_img_paths.sort()\n",
    "all_hs4_img_paths = sorted(all_hs4_img_paths, key=extract_patient_number)\n",
    "\n",
    "print(len(all_hs4_img_paths))\n",
    "print(all_hs4_img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8291a09",
   "metadata": {
    "papermill": {
     "duration": 0.014262,
     "end_time": "2025-04-08T09:20:50.939233",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.924971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Labels loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f793f737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:50.969453Z",
     "iopub.status.busy": "2025-04-08T09:20:50.969222Z",
     "iopub.status.idle": "2025-04-08T09:20:50.973302Z",
     "shell.execute_reply": "2025-04-08T09:20:50.972478Z"
    },
    "papermill": {
     "duration": 0.020777,
     "end_time": "2025-04-08T09:20:50.974462",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.953685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "all_labels = []\n",
    "for all_us_img_path in all_us_img_paths:\n",
    "    if \"Benign\" in all_us_img_path:\n",
    "        all_label = \"benign\"\n",
    "    elif \"Malignant\" in all_us_img_path:\n",
    "        all_label = \"malignant\"\n",
    "    all_labels.append(all_label)\n",
    "print(len(all_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1080ada",
   "metadata": {
    "papermill": {
     "duration": 0.014156,
     "end_time": "2025-04-08T09:20:51.003149",
     "exception": false,
     "start_time": "2025-04-08T09:20:50.988993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Full dataset finalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d811a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:51.033282Z",
     "iopub.status.busy": "2025-04-08T09:20:51.033052Z",
     "iopub.status.idle": "2025-04-08T09:20:51.035755Z",
     "shell.execute_reply": "2025-04-08T09:20:51.035140Z"
    },
    "papermill": {
     "duration": 0.019008,
     "end_time": "2025-04-08T09:20:51.037009",
     "exception": false,
     "start_time": "2025-04-08T09:20:51.018001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all_dataset = base_dataset(True, all_us_img_paths, all_labels)\n",
    "#all_dataset_loader = DataLoader(all_dataset, batch_size = batch_size_1, shuffle = True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d2c6d5",
   "metadata": {
    "papermill": {
     "duration": 0.014164,
     "end_time": "2025-04-08T09:20:51.065819",
     "exception": false,
     "start_time": "2025-04-08T09:20:51.051655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **5 fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e1d32a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:51.094760Z",
     "iopub.status.busy": "2025-04-08T09:20:51.094509Z",
     "iopub.status.idle": "2025-04-08T09:20:51.101513Z",
     "shell.execute_reply": "2025-04-08T09:20:51.100768Z"
    },
    "papermill": {
     "duration": 0.022751,
     "end_time": "2025-04-08T09:20:51.102650",
     "exception": false,
     "start_time": "2025-04-08T09:20:51.079899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating K-Fold splits...\n"
     ]
    }
   ],
   "source": [
    "splits_file_path = \"/kaggle/working/kfold_splits.json\"\n",
    "if not os.path.exists(splits_file_path):\n",
    "    print(\"Generating K-Fold splits...\")\n",
    "\n",
    "    splits = {}\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(all_us_img_paths)):\n",
    "        # Get the corresponding labels for train and val indices\n",
    "        train_labels = [all_labels[idx] for idx in train_idx]\n",
    "        val_labels = [all_labels[idx] for idx in val_idx]\n",
    "\n",
    "        splits[fold] = {\n",
    "            'train_idx': train_idx.tolist(),\n",
    "            'train_labels': train_labels,\n",
    "            'val_idx': val_idx.tolist(),\n",
    "            'val_labels': val_labels\n",
    "        }\n",
    "\n",
    "    # Dump the splits and labels to a JSON file\n",
    "    with open(splits_file_path, 'w') as f:\n",
    "        json.dump(splits, f)\n",
    "else:\n",
    "    print(f\"Splits file '{splits_file_path}' already exists, skipping generation.\")\n",
    "\n",
    "# Load the splits and labels from the json file\n",
    "with open(splits_file_path, 'r') as f:\n",
    "    splits = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68265f03",
   "metadata": {
    "papermill": {
     "duration": 0.014134,
     "end_time": "2025-04-08T09:20:51.132347",
     "exception": false,
     "start_time": "2025-04-08T09:20:51.118213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Training final**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aab807",
   "metadata": {
    "papermill": {
     "duration": 0.014116,
     "end_time": "2025-04-08T09:20:51.160960",
     "exception": false,
     "start_time": "2025-04-08T09:20:51.146844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Assistive functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52551f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:51.190292Z",
     "iopub.status.busy": "2025-04-08T09:20:51.190071Z",
     "iopub.status.idle": "2025-04-08T09:20:51.194511Z",
     "shell.execute_reply": "2025-04-08T09:20:51.193907Z"
    },
    "papermill": {
     "duration": 0.02044,
     "end_time": "2025-04-08T09:20:51.195686",
     "exception": false,
     "start_time": "2025-04-08T09:20:51.175246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_dataset_samples(dataset, num_samples=2):\n",
    "    for idx in range(num_samples):\n",
    "        sample = dataset[idx]\n",
    "        images = sample[:-1]\n",
    "        label = sample[-1] \n",
    "        fig, axes = plt.subplots(1, len(images), figsize=(20, 5))\n",
    "        for i in range(len(images)):\n",
    "            img = images[i].permute(1, 2, 0).numpy()\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(f'Image {i+1}')\n",
    "        plt.suptitle(f'Sample {idx} - Label: {label}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e6480b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:51.224809Z",
     "iopub.status.busy": "2025-04-08T09:20:51.224566Z",
     "iopub.status.idle": "2025-04-08T09:20:51.228506Z",
     "shell.execute_reply": "2025-04-08T09:20:51.227947Z"
    },
    "papermill": {
     "duration": 0.019673,
     "end_time": "2025-04-08T09:20:51.229618",
     "exception": false,
     "start_time": "2025-04-08T09:20:51.209945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_dataset_samples2(dataset, num_samples=2):\n",
    "    for idx in range(num_samples):\n",
    "        sample = dataset[idx]\n",
    "        images = sample[:-1]\n",
    "        label = sample[-1] \n",
    "        i=0\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(20, 5))\n",
    "        img = images[0].permute(1, 2, 0).numpy()\n",
    "        axes.imshow(img)\n",
    "        axes.axis('off')\n",
    "        axes.set_title(f'Image {i+1}')\n",
    "        plt.suptitle(f'Sample {idx} - Label: {label}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba077c",
   "metadata": {
    "papermill": {
     "duration": 0.01999,
     "end_time": "2025-04-08T09:20:51.264248",
     "exception": false,
     "start_time": "2025-04-08T09:20:51.244258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Main loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69aae12d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T09:20:51.293759Z",
     "iopub.status.busy": "2025-04-08T09:20:51.293518Z",
     "iopub.status.idle": "2025-04-08T10:51:57.921673Z",
     "shell.execute_reply": "2025-04-08T10:51:57.920832Z"
    },
    "papermill": {
     "duration": 5466.644426,
     "end_time": "2025-04-08T10:51:57.923214",
     "exception": false,
     "start_time": "2025-04-08T09:20:51.278788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca75c7dfd3b40d696111bbab2e2ca9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5505d9c6df4bf79836ebc16b80fc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5abdd9327fa497d90be89e958e974ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06645fa46662421984e9e5450617acb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Fold: 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs (Fold 1): 100%|\u001b[34m██████████\u001b[0m| 100/100 [17:17<00:00, 10.37s/epoch, model_saved_at_epoch=24, train_loss=0.0008, val_accuracy=0.8333]\n",
      "<ipython-input-60-47a343351e34>:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(Model_Path_Folds[fold]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall (Sensitivity): 1.0000\n",
      "Specificity: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Matthews Correlation Coefficient (MCC): 1.0000\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Fold: 2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs (Fold 2): 100%|\u001b[34m██████████\u001b[0m| 100/100 [18:40<00:00, 11.20s/epoch, model_saved_at_epoch=1, train_loss=0.0011, val_accuracy=1.0000]\n",
      "<ipython-input-60-47a343351e34>:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(Model_Path_Folds[fold]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall (Sensitivity): 1.0000\n",
      "Specificity: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Matthews Correlation Coefficient (MCC): 1.0000\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Fold: 3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs (Fold 3): 100%|\u001b[34m██████████\u001b[0m| 100/100 [18:20<00:00, 11.00s/epoch, model_saved_at_epoch=1, train_loss=0.0003, val_accuracy=1.0000]\n",
      "<ipython-input-60-47a343351e34>:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(Model_Path_Folds[fold]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall (Sensitivity): 1.0000\n",
      "Specificity: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Matthews Correlation Coefficient (MCC): 1.0000\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Fold: 4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs (Fold 4): 100%|\u001b[34m██████████\u001b[0m| 100/100 [18:21<00:00, 11.02s/epoch, model_saved_at_epoch=1, train_loss=0.0018, val_accuracy=1.0000]\n",
      "<ipython-input-60-47a343351e34>:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(Model_Path_Folds[fold]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall (Sensitivity): 1.0000\n",
      "Specificity: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Matthews Correlation Coefficient (MCC): 1.0000\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Fold: 5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs (Fold 5): 100%|\u001b[34m██████████\u001b[0m| 100/100 [18:15<00:00, 10.95s/epoch, model_saved_at_epoch=1, train_loss=0.0003, val_accuracy=1.0000]\n",
      "<ipython-input-60-47a343351e34>:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(Model_Path_Folds[fold]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall (Sensitivity): 1.0000\n",
      "Specificity: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Matthews Correlation Coefficient (MCC): 1.0000\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Average Accuracy: 1.0000\n",
      "Average Precision: 1.0000\n",
      "Average Recall (Sensitivity): 1.0000\n",
      "Average Specificity: 1.0000\n",
      "Average F1 Score: 1.0000\n",
      "Average Matthews Correlation Coefficient (MCC): 1.0000\n"
     ]
    }
   ],
   "source": [
    "total_val_accuracy = 0\n",
    "total_val_precision = 0\n",
    "total_val_recall = 0\n",
    "total_val_specificity = 0\n",
    "total_val_f1 = 0\n",
    "total_val_mcc = 0\n",
    "val_accuracy =0 \n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"\\n\")\n",
    "for fold in range(0,k_folds):\n",
    "    best_val_acc = 0\n",
    "    model = q_former()\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs, eta_min=0.0, last_epoch=-1, verbose='deprecated')\n",
    "    train_idx = splits[str(fold)]['train_idx']\n",
    "    train_labels = splits[str(fold)]['train_labels']\n",
    "    val_idx = splits[str(fold)]['val_idx']\n",
    "    val_labels = splits[str(fold)]['val_labels']\n",
    "    train_subset_text_in = Subset(all_text_in, train_idx)\n",
    "    train_subset_text_out = Subset(text_out, train_idx)\n",
    "    train_subset_us = Subset(all_us_img_paths, train_idx)\n",
    "    train_subset_mm1 = Subset(all_mm1_img_paths, train_idx)\n",
    "    train_subset_mm2 = Subset(all_mm2_img_paths, train_idx)\n",
    "    train_subset_hs1 = Subset(all_hs1_img_paths, train_idx)\n",
    "    train_subset_hs2 = Subset(all_hs2_img_paths, train_idx)\n",
    "    train_subset_hs3 = Subset(all_hs3_img_paths, train_idx)\n",
    "    train_subset_hs4 = Subset(all_hs4_img_paths, train_idx)\n",
    "    val_subset_text_in = Subset(all_text_in, val_idx)\n",
    "    val_subset_text_out = Subset(text_out, val_idx)\n",
    "    val_subset_us = Subset(all_us_img_paths, val_idx)\n",
    "    \n",
    "    train_subset_all = base_dataset(\n",
    "        True,\n",
    "        texts_in=train_subset_text_in,\n",
    "        texts_out=train_subset_text_out,\n",
    "        img_paths_1=train_subset_us,\n",
    "        img_paths_2=train_subset_mm1,\n",
    "        img_paths_3=train_subset_mm2,\n",
    "        img_paths_4=train_subset_hs1,\n",
    "        img_paths_5=train_subset_hs2,\n",
    "        img_paths_6=train_subset_hs3,\n",
    "        img_paths_7=train_subset_hs4,\n",
    "        labels=train_labels\n",
    "    )\n",
    "    #plot_dataset_samples(train_subset_all, num_samples=2)\n",
    "    val_subset = base_dataset(\n",
    "        False,\n",
    "        texts_in=val_subset_text_in,\n",
    "        texts_out=val_subset_text_out,\n",
    "        img_paths_1=val_subset_us,\n",
    "        img_paths_2=None,\n",
    "        img_paths_3=None,\n",
    "        img_paths_4=None,\n",
    "        img_paths_5=None,\n",
    "        img_paths_6=None,\n",
    "        img_paths_7=None,\n",
    "        labels=val_labels\n",
    "    )\n",
    "    train_dataset_loader = DataLoader(train_subset_all, batch_size = batch_size_1, shuffle = True, num_workers=0, pin_memory=True)\n",
    "    val_dataset_loader = DataLoader(val_subset, batch_size = 1, shuffle = False, num_workers=0, pin_memory=True)\n",
    "    #plot_dataset_samples2(val_subset, num_samples=6)\n",
    "\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(f\"Fold: {fold+1}\")\n",
    "    print(\"\\n\")\n",
    "    pbar = tqdm(range(1, epochs + 1), desc=f\"Epochs (Fold {fold + 1})\", unit=\"epoch\", colour='blue')\n",
    "    for epoch in pbar:\n",
    "        train_loss = train_function(train_dataset_loader, model, classification_loss1, optimizer, epoch, device = device)\n",
    "        scheduler.step()\n",
    "        #exec(f\"train_losses_fold{fold + 1}.append(train_loss)\")\n",
    "        val_accuracy, val_precision, val_recall, val_specificity, val_f1, val_mcc = validator(val_dataset_loader, model, device)\n",
    "        #exec(f\"valid_accuracy_scores_fold{fold + 1}.append(val_accuracy)\")\n",
    "        if(best_val_acc<val_accuracy):\n",
    "            save = epoch\n",
    "            best_val_acc = val_accuracy\n",
    "            torch.save(model.state_dict(),Model_Path_Folds[fold])\n",
    "        pbar.set_postfix(train_loss=f\"{train_loss:.4f}\", val_accuracy=f\"{val_accuracy:.4f}\", model_saved_at_epoch=f\"{save}\", refresh=True)\n",
    "    model = q_former()\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(Model_Path_Folds[fold]))\n",
    "    val_accuracy = 0\n",
    "    val_precision = 0\n",
    "    val_recall = 0\n",
    "    val_specificity = 0\n",
    "    val_f1 = 0\n",
    "    val_mcc = 0\n",
    "    val_accuracy, val_precision, val_recall, val_specificity, val_f1, val_mcc = validator(val_dataset_loader, model, device)\n",
    "    print(f'Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'Precision: {val_precision:.4f}')\n",
    "    print(f'Recall (Sensitivity): {val_recall:.4f}')\n",
    "    print(f'Specificity: {val_specificity:.4f}')\n",
    "    print(f'F1 Score: {val_f1:.4f}')\n",
    "    print(f'Matthews Correlation Coefficient (MCC): {val_mcc:.4f}')\n",
    "    total_val_accuracy += val_accuracy * len(val_idx)\n",
    "    total_val_precision += val_precision * len(val_idx)\n",
    "    total_val_recall += val_recall * len(val_idx)\n",
    "    total_val_specificity += val_specificity * len(val_idx)\n",
    "    total_val_f1 += val_f1 * len(val_idx)\n",
    "    total_val_mcc += val_mcc * len(val_idx)\n",
    "print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"\\n\")\n",
    "\n",
    "avg_val_accuracy = total_val_accuracy / (len(train_idx) + len(val_idx))\n",
    "avg_val_precision = total_val_precision / (len(train_idx) + len(val_idx))\n",
    "avg_val_recall = total_val_recall / (len(train_idx) + len(val_idx))\n",
    "avg_val_specificity = total_val_specificity / (len(train_idx) + len(val_idx))\n",
    "avg_val_f1 = total_val_f1 / (len(train_idx) + len(val_idx))\n",
    "avg_val_mcc = total_val_mcc / (len(train_idx) + len(val_idx))\n",
    "\n",
    "print(f'Average Accuracy: {avg_val_accuracy:.4f}')\n",
    "print(f'Average Precision: {avg_val_precision:.4f}')\n",
    "print(f'Average Recall (Sensitivity): {avg_val_recall:.4f}')\n",
    "print(f'Average Specificity: {avg_val_specificity:.4f}')\n",
    "print(f'Average F1 Score: {avg_val_f1:.4f}')\n",
    "print(f'Average Matthews Correlation Coefficient (MCC): {avg_val_mcc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde48f0b",
   "metadata": {
    "papermill": {
     "duration": 0.058851,
     "end_time": "2025-04-08T10:51:58.042302",
     "exception": false,
     "start_time": "2025-04-08T10:51:57.983451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9dbe709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T10:51:58.161088Z",
     "iopub.status.busy": "2025-04-08T10:51:58.160544Z",
     "iopub.status.idle": "2025-04-08T10:52:17.481664Z",
     "shell.execute_reply": "2025-04-08T10:52:17.480812Z"
    },
    "papermill": {
     "duration": 19.382359,
     "end_time": "2025-04-08T10:52:17.483225",
     "exception": false,
     "start_time": "2025-04-08T10:51:58.100866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-grad-cam'...\r\n",
      "remote: Enumerating objects: 1338, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (183/183), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (127/127), done.\u001b[K\r\n",
      "remote: Total 1338 (delta 128), reused 61 (delta 55), pack-reused 1155 (from 3)\u001b[K\r\n",
      "Receiving objects: 100% (1338/1338), 137.57 MiB | 23.05 MiB/s, done.\r\n",
      "Resolving deltas: 100% (755/755), done.\r\n",
      "Obtaining file:///kaggle/working/pytorch-grad-cam\r\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from grad-cam==1.5.5) (1.26.4)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from grad-cam==1.5.5) (11.0.0)\r\n",
      "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from grad-cam==1.5.5) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from grad-cam==1.5.5) (0.20.1+cu121)\r\n",
      "Collecting ttach (from grad-cam==1.5.5)\r\n",
      "  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from grad-cam==1.5.5) (4.67.1)\r\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from grad-cam==1.5.5) (4.10.0.84)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from grad-cam==1.5.5) (3.7.5)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from grad-cam==1.5.5) (1.2.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam==1.5.5) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.1->grad-cam==1.5.5) (1.3.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam==1.5.5) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam==1.5.5) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam==1.5.5) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam==1.5.5) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam==1.5.5) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam==1.5.5) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam==1.5.5) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->grad-cam==1.5.5) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->grad-cam==1.5.5) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->grad-cam==1.5.5) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->grad-cam==1.5.5) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->grad-cam==1.5.5) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->grad-cam==1.5.5) (2.4.1)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam==1.5.5) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam==1.5.5) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam==1.5.5) (3.5.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam==1.5.5) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->grad-cam==1.5.5) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->grad-cam==1.5.5) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->grad-cam==1.5.5) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->grad-cam==1.5.5) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->grad-cam==1.5.5) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->grad-cam==1.5.5) (2024.2.0)\r\n",
      "Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\r\n",
      "Building wheels for collected packages: grad-cam\r\n",
      "  Building editable for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for grad-cam: filename=grad_cam-1.5.5-0.editable-py3-none-any.whl size=10311 sha256=3698be9bde16ea4cf8e37823530e906b025fe9b672ccc4153ebd3924999f3fc1\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-te9hpf1j/wheels/72/e0/c8/5126ff2f404cd8f0d453bc07d705c8736e39d966eb4f5342b2\r\n",
      "Successfully built grad-cam\r\n",
      "Installing collected packages: ttach, grad-cam\r\n",
      "Successfully installed grad-cam-1.5.5 ttach-0.0.3\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jacobgil/pytorch-grad-cam.git\n",
    "!pip install -e /kaggle/working/pytorch-grad-cam\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/pytorch-grad-cam')\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "class SemanticSegmentationTarget:\n",
    "    def __init__(self, category, mask):\n",
    "        self.category = category\n",
    "        self.mask = torch.from_numpy(mask)\n",
    "        if torch.cuda.is_available():\n",
    "            self.mask = self.mask.cuda()\n",
    "        \n",
    "    def __call__(self, model_output):\n",
    "        return (model_output[self.category, :, : ] * self.mask).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f451385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T10:52:17.609151Z",
     "iopub.status.busy": "2025-04-08T10:52:17.608847Z",
     "iopub.status.idle": "2025-04-08T10:52:17.621415Z",
     "shell.execute_reply": "2025-04-08T10:52:17.620742Z"
    },
    "papermill": {
     "duration": 0.076218,
     "end_time": "2025-04-08T10:52:17.622474",
     "exception": false,
     "start_time": "2025-04-08T10:52:17.546256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_predictions_and_heatmap(k_folds, all_us_img_paths, all_text_in, text_out, splits, Model_Path_Folds, device, class_names):\n",
    "    for fold in range(0, k_folds):\n",
    "        print(f\"\\n==================== Fold {fold + 1} ====================\")\n",
    "        model = q_former()\n",
    "        model = model.to(device)\n",
    "        model.load_state_dict(torch.load(Model_Path_Folds[fold]))\n",
    "        model.eval()\n",
    "        val_idx = splits[str(fold)]['val_idx']\n",
    "        val_labels = splits[str(fold)]['val_labels']\n",
    "        val_subset = Subset(all_us_img_paths, val_idx)\n",
    "        val_subset_text_in = Subset(all_text_in, val_idx)\n",
    "        val_subset_text_out = Subset(text_out, val_idx)\n",
    "        val_subset = base_dataset(False, texts_in = val_subset_text_in, texts_out= val_subset_text_out, img_paths_1=val_subset, img_paths_2=None, img_paths_3=None, img_paths_4=None, img_paths_5=None, img_paths_6=None, img_paths_7=None, labels=val_labels)\n",
    "        val_dataset_loader = DataLoader(val_subset, batch_size = 1, shuffle = False, num_workers=0, pin_memory=True)\n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        fig, axs = plt.subplots(2, min(6, len(val_idx)), figsize=(15, 5))\n",
    "        \n",
    "        target_layer = [model.vision.encoder_ultrasound.model.stages[3]]\n",
    "\n",
    "        for idx, (inputs, input_ids, labels) in enumerate(val_dataset_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            input_ids = input_ids.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs, pred_slm = model(input_ids, inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "            preds = preds.item()\n",
    "            reverse_class_index = {v: k for k, v in class_index.items()}\n",
    "            preds = reverse_class_index[preds]\n",
    "            labels = labels[0]\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "            \n",
    "            if idx < len(axs[1]):\n",
    "                img = inputs.cpu().squeeze().permute(1, 2, 0)\n",
    "                axs[0,idx].imshow(img, cmap='gray')\n",
    "                axs[0,idx].axis('off')\n",
    "                axs[0,idx].set_title(f\"Pred: {preds}\\nActual: {labels}\")\n",
    "            if idx < len(axs[1]):\n",
    "                cam = GradCAM(model=model.vision.encoder_ultrasound, target_layers=target_layer)\n",
    "                grayscale_cam = cam(input_tensor=inputs)[0, :]\n",
    "                img = inputs.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "                cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "                axs[1,idx].imshow(cam_image, cmap='hot', alpha=0.9) \n",
    "                axs[1,idx].axis('off')\n",
    "                axs[1,idx].set_title(f\"Grad-CAM Image\")\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_index)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_index, yticklabels=class_index)\n",
    "        plt.title(f'Confusion Matrix - Fold {fold + 1}')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e5481a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T10:52:17.746303Z",
     "iopub.status.busy": "2025-04-08T10:52:17.746048Z",
     "iopub.status.idle": "2025-04-08T10:52:20.294194Z",
     "shell.execute_reply": "2025-04-08T10:52:20.292916Z"
    },
    "papermill": {
     "duration": 2.611046,
     "end_time": "2025-04-08T10:52:20.295375",
     "exception": true,
     "start_time": "2025-04-08T10:52:17.684329",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Fold 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-6b8d543189db>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(Model_Path_Folds[fold]))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-5bcc6938c1e9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_predictions_and_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_us_img_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_text_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel_Path_Folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-6b8d543189db>\u001b[0m in \u001b[0;36mplot_predictions_and_heatmap\u001b[0;34m(k_folds, all_us_img_paths, all_text_in, text_out, splits, Model_Path_Folds, device, class_names)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_slm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions_and_heatmap(k_folds, all_us_img_paths, all_text_in, text_out, splits, Model_Path_Folds, device, class_index)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6880798,
     "sourceId": 11125557,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5530.481348,
   "end_time": "2025-04-08T10:52:23.614541",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-08T09:20:13.133193",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0003222663b142c4a5a2b67498fe0a83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6823f881bc1543a7a7943e67c7d1e4ce",
       "placeholder": "​",
       "style": "IPY_MODEL_f8d973ad99d64337b85daf210f649616",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "00821fbff88e40299ba4401a5b789084": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1e430e52c79e4cf8894bd2bed84dceae",
       "placeholder": "​",
       "style": "IPY_MODEL_615dfa1608f442598b5a9d797e3aa23c",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "063bbca9fc2f4c2babada0f16d698c67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f78fb375d8a4f29896cca3d05e1adb9",
       "max": 276059044.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3e56605421b64de79207f92442ab83c7",
       "tabbable": null,
       "tooltip": null,
       "value": 276059044.0
      }
     },
     "06645fa46662421984e9e5450617acb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0003222663b142c4a5a2b67498fe0a83",
        "IPY_MODEL_5740db6db5f94dd6870261129ae54aa0",
        "IPY_MODEL_68c71b233f4642cea0243e2010a4af3f"
       ],
       "layout": "IPY_MODEL_f28c6dc46195488cb368c032e40521e8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "11d94389b52440bb9db42fcf803c60d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "121e47f5b46a4013a32d12d40e4ad255": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1274f2ae74494097bede6794e818277c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e430e52c79e4cf8894bd2bed84dceae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1f78fb375d8a4f29896cca3d05e1adb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ce92d331ef3447a8fe073669bb57c17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_90326c6408644504b0fe993f16bbbd55",
       "placeholder": "​",
       "style": "IPY_MODEL_6267feefed9a4073971ce69f6da0d5e5",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "2cf1f77d30ec48d49ade0878ec03a686": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "304fc913ded94cac9b75dabd54dbaf79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "309db45e40264ea8baf288425bbe504f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3134d6c2dbdd4d378dd158ed7c96d8dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1274f2ae74494097bede6794e818277c",
       "max": 48.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c3304779497540bfaae435290cc4a124",
       "tabbable": null,
       "tooltip": null,
       "value": 48.0
      }
     },
     "3b729445120f4801a38f8acd89f81321": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_309db45e40264ea8baf288425bbe504f",
       "placeholder": "​",
       "style": "IPY_MODEL_403a532f68b84edfba513a1eb16aad8a",
       "tabbable": null,
       "tooltip": null,
       "value": " 466k/466k [00:00&lt;00:00, 1.27MB/s]"
      }
     },
     "3e56605421b64de79207f92442ab83c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "403a532f68b84edfba513a1eb16aad8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "40522016d7c648ba98a81b06ebbcdda2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a1671286dd6d4111a461bcdebd947d8d",
       "placeholder": "​",
       "style": "IPY_MODEL_121e47f5b46a4013a32d12d40e4ad255",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "4ca75c7dfd3b40d696111bbab2e2ca9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_00821fbff88e40299ba4401a5b789084",
        "IPY_MODEL_3134d6c2dbdd4d378dd158ed7c96d8dd",
        "IPY_MODEL_e3a75f8da2914a8c96868b95f55681bf"
       ],
       "layout": "IPY_MODEL_ed91f93482f64a6e98cf8d36778931dc",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5740db6db5f94dd6870261129ae54aa0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e7a0fc90a0254b249953e79bb5d46992",
       "max": 570.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e5cd323ca5ab4d82bafac395783e2e5e",
       "tabbable": null,
       "tooltip": null,
       "value": 570.0
      }
     },
     "5a1f35b6a3664e4982bc00300d0195bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "615dfa1608f442598b5a9d797e3aa23c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6267feefed9a4073971ce69f6da0d5e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "635d4f74504b4fe68e1db5bd2d0b54c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67c1cc899a234f8c8691a871deae0398": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6823f881bc1543a7a7943e67c7d1e4ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "685db793e2e64d59b5c1c7729468eb08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5a1f35b6a3664e4982bc00300d0195bf",
       "placeholder": "​",
       "style": "IPY_MODEL_c1e89db96fcb4e4aa19c325a40baf326",
       "tabbable": null,
       "tooltip": null,
       "value": " 232k/232k [00:00&lt;00:00, 666kB/s]"
      }
     },
     "68c71b233f4642cea0243e2010a4af3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d69fd698db2b4320ac6554b13d9a1698",
       "placeholder": "​",
       "style": "IPY_MODEL_e3b09e526e454a0099c8b087bf81d7f5",
       "tabbable": null,
       "tooltip": null,
       "value": " 570/570 [00:00&lt;00:00, 59.6kB/s]"
      }
     },
     "6c24c7e164b64aa7916d01ca8cdbca66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7170d481b7774d1ea94a3202f5a3203b",
       "placeholder": "​",
       "style": "IPY_MODEL_b339021bd70e47fb86140ca55b103acd",
       "tabbable": null,
       "tooltip": null,
       "value": " 276M/276M [00:09&lt;00:00, 28.4MB/s]"
      }
     },
     "7170d481b7774d1ea94a3202f5a3203b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73053e06a359437bbbbbb51fdbf84f0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_304fc913ded94cac9b75dabd54dbaf79",
       "placeholder": "​",
       "style": "IPY_MODEL_11d94389b52440bb9db42fcf803c60d7",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "7964009d034e47c7bbe9f1cc7a93fd13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8796cda990f04aee84b89d46baf9eced": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e618ab0a73740f69d1ee2ff0a11800f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8e69ecec28064ca2bb39b5cf6ab48b4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "90326c6408644504b0fe993f16bbbd55": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a1671286dd6d4111a461bcdebd947d8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aac86ec5bd1344d4a7442a585450d513": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ac5505d9c6df4bf79836ebc16b80fc58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_73053e06a359437bbbbbb51fdbf84f0d",
        "IPY_MODEL_ebb92723ab0a4979b339de893992902c",
        "IPY_MODEL_685db793e2e64d59b5c1c7729468eb08"
       ],
       "layout": "IPY_MODEL_2cf1f77d30ec48d49ade0878ec03a686",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b339021bd70e47fb86140ca55b103acd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c1e89db96fcb4e4aa19c325a40baf326": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c3304779497540bfaae435290cc4a124": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c5abdd9327fa497d90be89e958e974ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2ce92d331ef3447a8fe073669bb57c17",
        "IPY_MODEL_ecbe0bc7893749e8a77ee0cf1c942b4e",
        "IPY_MODEL_3b729445120f4801a38f8acd89f81321"
       ],
       "layout": "IPY_MODEL_67c1cc899a234f8c8691a871deae0398",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d17d7a30b81842ebbc760537f62c27e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d69fd698db2b4320ac6554b13d9a1698": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3a75f8da2914a8c96868b95f55681bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_635d4f74504b4fe68e1db5bd2d0b54c0",
       "placeholder": "​",
       "style": "IPY_MODEL_8e69ecec28064ca2bb39b5cf6ab48b4b",
       "tabbable": null,
       "tooltip": null,
       "value": " 48.0/48.0 [00:00&lt;00:00, 4.97kB/s]"
      }
     },
     "e3b09e526e454a0099c8b087bf81d7f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e5cd323ca5ab4d82bafac395783e2e5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e7a0fc90a0254b249953e79bb5d46992": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebb92723ab0a4979b339de893992902c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7964009d034e47c7bbe9f1cc7a93fd13",
       "max": 231508.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aac86ec5bd1344d4a7442a585450d513",
       "tabbable": null,
       "tooltip": null,
       "value": 231508.0
      }
     },
     "ecbe0bc7893749e8a77ee0cf1c942b4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8796cda990f04aee84b89d46baf9eced",
       "max": 466062.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8e618ab0a73740f69d1ee2ff0a11800f",
       "tabbable": null,
       "tooltip": null,
       "value": 466062.0
      }
     },
     "ed91f93482f64a6e98cf8d36778931dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f28c6dc46195488cb368c032e40521e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8d973ad99d64337b85daf210f649616": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fceb78fc735744bfbd7e293eca98a830": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_40522016d7c648ba98a81b06ebbcdda2",
        "IPY_MODEL_063bbca9fc2f4c2babada0f16d698c67",
        "IPY_MODEL_6c24c7e164b64aa7916d01ca8cdbca66"
       ],
       "layout": "IPY_MODEL_d17d7a30b81842ebbc760537f62c27e7",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
